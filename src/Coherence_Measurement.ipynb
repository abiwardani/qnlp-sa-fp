{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e14f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Parameters\n",
    "\n",
    "# Experiment conditions\n",
    "# rewriter rules\n",
    "use_all_rewriter_rules = True\n",
    "\n",
    "# bigraph method\n",
    "convert_bigraph = True\n",
    "\n",
    "# NOT box model\n",
    "not_representation = \"X\"\n",
    "not_placement = \"end\"\n",
    "\n",
    "# train NOT sentences\n",
    "train_not_sentences = True\n",
    "\n",
    "# load params\n",
    "train_params = False\n",
    "load_params = False\n",
    "\n",
    "# training hyperparams\n",
    "# SPSA hyperparams\n",
    "spsa_a = 0.2\n",
    "spsa_c = 0.06\n",
    "# gamma = 0.928382463478119\n",
    "spsa_n_iter = 130\n",
    "\n",
    "# SVM type\n",
    "kernel = 'rbf'\n",
    "default_svm = True\n",
    "optimize_svm = False\n",
    "\n",
    "# Experiment metadata\n",
    "experiment_name = \"coherence_measurement\"\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31bf0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if (experiment_name == \"\"):\n",
    "    experiment_name = \"misc\"\n",
    "\n",
    "path = '../data/experiment_results/'+experiment_name\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except:\n",
    "    print(\"experiment folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c950b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fba1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8e7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_data(filename):\n",
    "    labels, sentences = [], []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            labels.append([1, 0] if line[0] == '1' else [0, 1])\n",
    "            sentences.append(line[1:].strip())\n",
    "    return np.array(labels), sentences\n",
    "\n",
    "test_targets_src, test_data_src = read_data('../data/datasets/restaurant_v3_test.txt')\n",
    "\n",
    "dev_targets_src, dev_data_src = read_data('../data/datasets/restaurant_v3_dev.txt')\n",
    "train_targets_src, train_data_src = read_data('../data/datasets/restaurant_v3_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ab1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for converting to bigraph\n",
    "\n",
    "from discopy.rigid import Id\n",
    "''\n",
    "def checkTrailingCups(diagram):\n",
    "    scanWords = True\n",
    "    \n",
    "    for box in diagram.boxes:\n",
    "        if not box.dom and not scanWords:\n",
    "            return False\n",
    "        else:\n",
    "            scanWords = scanWords and not box.dom\n",
    "    \n",
    "    return True\n",
    "\n",
    "def convertToTrailingCups(diagram):\n",
    "    if (checkTrailingCups(diagram)):\n",
    "        return diagram\n",
    "\n",
    "    words = []\n",
    "    cups = []\n",
    "    \n",
    "    for box in diagram.boxes:\n",
    "        if not box.dom:\n",
    "            words = words + [box]\n",
    "        else:\n",
    "            cups = [box] + cups\n",
    "    \n",
    "    new_diag = words[0]\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if i != 0:\n",
    "            new_diag = new_diag >> Id(new_diag.cod) @ word\n",
    "    \n",
    "    for i, cup in enumerate(cups):\n",
    "        if i != len(cups)-1:\n",
    "            new_diag = new_diag >> Id(new_diag.cod[:-2]) @ cup\n",
    "        else:\n",
    "            new_diag = new_diag >> cup @ Id(new_diag.cod[2:])\n",
    "    \n",
    "    return new_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbe9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion for stemming and lemmatization of tokens\n",
    "\n",
    "def to_word_tokens(data):\n",
    "    return [word_tokenize(record) for record in data]\n",
    "\n",
    "def build_stem_dictionary(data):\n",
    "    port = PorterStemmer()\n",
    "    wnet = WordNetLemmatizer()\n",
    "    \n",
    "    mapping = {}\n",
    "    \n",
    "    data_as_tokens = to_word_tokens(data)\n",
    "    \n",
    "    for words in data_as_tokens:\n",
    "        for word in words:\n",
    "            if word not in mapping:\n",
    "                stemmed_word = port.stem(word)\n",
    "                lemmatized_word = wnet.lemmatize(stemmed_word)\n",
    "                \n",
    "                mapping[word] = lemmatized_word\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6454a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for stemming and lemmatization of diagram boxes\n",
    "\n",
    "from lambeq.rewrite import RewriteRule\n",
    "\n",
    "class StemRewriteRule(RewriteRule):\n",
    "    def __init__(self, data):\n",
    "        self.mapping = build_stem_dictionary(data)\n",
    "    \n",
    "    def matches(self, box):\n",
    "        return box.name in self.mapping\n",
    "\n",
    "    def rewrite(self, box):\n",
    "        new_name = self.mapping[box.name]\n",
    "        return type(box)(name=new_name, dom=box.dom, cod=box.cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85c3fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq.ansatz import CircuitAnsatz\n",
    "from abc import abstractmethod\n",
    "# from collections.abc import Mapping\n",
    "from itertools import cycle\n",
    "from typing import Callable, Optional, Tuple, Mapping\n",
    "from discopy.quantum.circuit import (Circuit, Discard, Functor, Id, qubit)\n",
    "from discopy.quantum.gates import Bra, H, Ket, Rx, Ry, Rz\n",
    "from discopy.rigid import Box, Diagram, Ty\n",
    "from discopy.tensor import Dim, Tensor\n",
    "import numpy as np\n",
    "from sympy import Symbol, symbols\n",
    "\n",
    "class SimpleSA(Circuit):\n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import H, Rx, Rz, CX, Ry\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            if len(params) == 0:\n",
    "                circuit = Id(1)\n",
    "            else:\n",
    "                circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "        elif len(Tensor.np.shape(params)) != 2\\\n",
    "                or Tensor.np.shape(params)[1] != n_qubits - 1:\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits - 1))\n",
    "        else:\n",
    "            depth = Tensor.np.shape(params)[0]\n",
    "            circuit = Id(n_qubits)\n",
    "\n",
    "            for thetas in params:\n",
    "                hadamards = Id().tensor(*(n_qubits * [H]))\n",
    "                rotations = Id(n_qubits).then(*(\n",
    "                    (Id(i) @ CX @ Id(n_qubits - 2 - i)) >> (Id(i + 1) @ Rz(thetas[i]) @ Id(n_qubits - 2 - i) >> (Id(i + 1) @ H @ Id(n_qubits - 2 - i)))\n",
    "                    for i in range(n_qubits - 1)))\n",
    "                circuit >>= hadamards >> rotations\n",
    "\n",
    "        super().__init__(circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class SimpleSAAnsatz(CircuitAnsatz):\n",
    "    def __init__(self, ob_map: Mapping[Ty, int], n_layers: int, n_single_qubit_params: int = 0, discard: bool = False) -> None:\n",
    "        super().__init__(ob_map, n_layers, n_single_qubit_params, SimpleSA, discard, [Rx, Rz], H)\n",
    "\n",
    "    def params_shape(self, n_qubits: int) -> Tuple[int, ...]:\n",
    "        return (self.n_layers, n_qubits - 1)\n",
    "\n",
    "class Sim15SA(Circuit):\n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import CX, Ry\n",
    "\n",
    "        params_shape = Tensor.np.shape(params)\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            circuit = Id()\n",
    "        elif (len(params_shape) != 2) or (params_shape[1] != 2 * n_qubits):\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(2 * n_qubits))\n",
    "        else:\n",
    "            depth = params_shape[0]\n",
    "            circuit = Id(n_qubits)\n",
    "\n",
    "            for thetas in params:\n",
    "                sublayer1 = Id().tensor(*map(Ry, thetas[:n_qubits]))\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    src = i\n",
    "                    tgt = (i - 1) % n_qubits\n",
    "                    sublayer1 = sublayer1.CX(src, tgt)\n",
    "\n",
    "                sublayer2 = Id().tensor(*map(Ry, thetas[n_qubits:]))\n",
    "\n",
    "                for i in range(n_qubits, 0, -1):\n",
    "                    src = i % n_qubits\n",
    "                    tgt = (i + 1) % n_qubits\n",
    "                    sublayer2 = sublayer2.CX(src, tgt)\n",
    "\n",
    "                circuit >>= sublayer1 >> sublayer2\n",
    "\n",
    "        super().__init__(\n",
    "            circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class Sim15SAAnsatz(CircuitAnsatz):\n",
    "    def __init__(self, ob_map: Mapping[Ty, int], n_layers: int, n_single_qubit_params: int = 0, discard: bool = False) -> None:\n",
    "        super().__init__(ob_map, n_layers, n_single_qubit_params, Sim15SA, discard, [Rx, Rz])\n",
    "\n",
    "    def params_shape(self, n_qubits: int) -> Tuple[int, ...]:\n",
    "        return (self.n_layers, 2 * n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76391143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCRxLayer(Circuit):\n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import H, CRx\n",
    "\n",
    "        params_shape = Tensor.np.shape(params)\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            # circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "            circuit = Id(1)\n",
    "        elif (len(params_shape) != 2) or (params_shape[1] != n_qubits):\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits))\n",
    "        else:\n",
    "            depth = params_shape[0]\n",
    "            circuit = Id(n_qubits)\n",
    "\n",
    "            for thetas in params:\n",
    "                sublayer1 = Id().tensor(*([H for _ in range(n_qubits)]))\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    src = i\n",
    "                    tgt = (i - 1) % n_qubits\n",
    "                    sublayer1 = sublayer1.CRx(thetas[i], src, tgt)\n",
    "\n",
    "                sublayer2 = Id().tensor(*([H for _ in range(n_qubits)]))\n",
    "\n",
    "                for i in range(n_qubits, 0, -1):\n",
    "                    src = i % n_qubits\n",
    "                    tgt = (i + 1) % n_qubits\n",
    "                    sublayer2 = sublayer2.CRx(thetas[-i], src, tgt)\n",
    "\n",
    "                circuit >>= sublayer1 >> sublayer2\n",
    "\n",
    "        super().__init__(\n",
    "            circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class HCRzLayer(Circuit):\n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import H, CRz\n",
    "\n",
    "        params_shape = Tensor.np.shape(params)\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            # circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "            circuit = Id(1)\n",
    "        elif (len(params_shape) != 2) or (params_shape[1] != n_qubits):\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits))\n",
    "        else:\n",
    "            depth = params_shape[0]\n",
    "            circuit = Id(n_qubits)\n",
    "\n",
    "            for thetas in params:\n",
    "                sublayer1 = Id().tensor(*([H for _ in range(n_qubits)]))\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    src = i\n",
    "                    tgt = (i - 1) % n_qubits\n",
    "                    sublayer1 = sublayer1.CRz(thetas[i], src, tgt)\n",
    "\n",
    "                sublayer2 = Id().tensor(*([H for _ in range(n_qubits)]))\n",
    "\n",
    "                for i in range(n_qubits, 0, -1):\n",
    "                    src = i % n_qubits\n",
    "                    tgt = (i + 1) % n_qubits\n",
    "                    sublayer2 = sublayer2.CRz(thetas[-i], src, tgt)\n",
    "\n",
    "                circuit >>= sublayer1 >> sublayer2\n",
    "\n",
    "        super().__init__(\n",
    "            circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class HCRxLayerV2(Circuit):\n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import H, CRx\n",
    "\n",
    "        params_shape = Tensor.np.shape(params)\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            # circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "            circuit = Id(1)\n",
    "        elif (len(params_shape) != 2) or (params_shape[1] != 2*n_qubits):\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits))\n",
    "        else:\n",
    "            depth = params_shape[0]\n",
    "            circuit = Id(n_qubits)\n",
    "\n",
    "            for thetas in params:\n",
    "                sublayer1 = Id().tensor(*([H for _ in range(n_qubits)]))\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    src = i\n",
    "                    tgt = (i - 1) % n_qubits\n",
    "                    sublayer1 = sublayer1.CRx(thetas[i], src, tgt)\n",
    "\n",
    "                sublayer2 = Id().tensor(*([H for _ in range(n_qubits)]))\n",
    "\n",
    "                for i in range(n_qubits, n_qubits*2):\n",
    "                    src = i % n_qubits\n",
    "                    tgt = (i + 1) % n_qubits\n",
    "                    sublayer2 = sublayer2.CRx(thetas[i], src, tgt)\n",
    "\n",
    "                circuit >>= sublayer1 >> sublayer2\n",
    "\n",
    "        super().__init__(\n",
    "            circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class HCRzLayerV2(Circuit):\n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import H, CRz\n",
    "\n",
    "        params_shape = Tensor.np.shape(params)\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            # circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "            circuit = Id(1)\n",
    "        elif (len(params_shape) != 2) or (params_shape[1] != 2*n_qubits):\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits))\n",
    "        else:\n",
    "            depth = params_shape[0]\n",
    "            circuit = Id(n_qubits)\n",
    "\n",
    "            for thetas in params:\n",
    "                sublayer1 = Id().tensor(*([H for _ in range(n_qubits)]))\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    src = i\n",
    "                    tgt = (i - 1) % n_qubits\n",
    "                    sublayer1 = sublayer1.CRz(thetas[i], src, tgt)\n",
    "\n",
    "                sublayer2 = Id().tensor(*([H for _ in range(n_qubits)]))\n",
    "\n",
    "                for i in range(n_qubits, 2*n_qubits, -1):\n",
    "                    src = i % n_qubits\n",
    "                    tgt = (i + 1) % n_qubits\n",
    "                    sublayer2 = sublayer2.CRz(thetas[i], src, tgt)\n",
    "\n",
    "                circuit >>= sublayer1 >> sublayer2\n",
    "\n",
    "        super().__init__(\n",
    "            circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class GeneralQCAnsatz(CircuitAnsatz):\n",
    "    def __init__(self, ob_map: Mapping[Ty, int], n_layers: int, n_single_qubit_params: int = 0, block_layer = HCRxLayer, discard: bool = False) -> None:\n",
    "        super().__init__(ob_map, n_layers, n_single_qubit_params, block_layer, discard, [Rx, Rz], H)\n",
    "\n",
    "    def params_shape(self, n_qubits: int) -> Tuple[int, ...]:\n",
    "        return (self.n_layers, n_qubits)\n",
    "\n",
    "class GeneralQCAnsatzV2(CircuitAnsatz):\n",
    "    def __init__(self, ob_map: Mapping[Ty, int], n_layers: int, n_single_qubit_params: int = 0, block_layer = HCRxLayerV2, discard: bool = False) -> None:\n",
    "        super().__init__(ob_map, n_layers, n_single_qubit_params, block_layer, discard, [Rx, Rz], H)\n",
    "\n",
    "    def params_shape(self, n_qubits: int) -> Tuple[int, ...]:\n",
    "        return (self.n_layers, 2*n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375e08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, Rewriter, remove_cups\n",
    "from discopy import grammar\n",
    "from discopy.quantum.gates import X, Z\n",
    "\n",
    "def sentences_to_circuits(sentences, ansatz, convert_bigraph=True, not_representation=\"X\", all_sentences=None, return_valids_mask=True):\n",
    "    ### SENTENCES TO DIAGRAMS ###\n",
    "\n",
    "    if all_sentences is None:\n",
    "        all_sentences = sentences\n",
    "    \n",
    "    # syntax tree parsing\n",
    "    parser = BobcatParser()\n",
    "    raw_diagrams = parser.sentences2diagrams([text.replace(\" not \", \" \") for text in sentences])\n",
    "\n",
    "    # filter valid diagrams type S\n",
    "    n_sent = len(sentences)\n",
    "\n",
    "    valids_mask = np.array([d.cod == Ty('s') for d in raw_diagrams])\n",
    "    data = [sentences[i] for i in range(n_sent) if valids_mask[i]]\n",
    "    use_diagrams = [raw_diagrams[i] for i in range(n_sent) if valids_mask[i]]\n",
    "\n",
    "    # bigraph method\n",
    "    rewriter = Rewriter()\n",
    "    rewritten_diagrams = [rewriter(diagram) for diagram in use_diagrams]\n",
    "\n",
    "    normalised_diagrams = [convertToTrailingCups(diagram.normal_form()) for diagram in rewritten_diagrams]\n",
    "\n",
    "    removed_diagrams = [remove_cups(diagram) for diagram in normalised_diagrams]\n",
    "\n",
    "    # stemming and lemmatization\n",
    "    stemmed_diagrams = [Rewriter([StemRewriteRule(all_sentences)])(diagram) for diagram in removed_diagrams]\n",
    "\n",
    "    # final diagrams\n",
    "    diagrams = [diagram for diagram in stemmed_diagrams]\n",
    "\n",
    "    ### DIAGRAMS to CIRCUITS ###\n",
    "\n",
    "    # string diagrams to raw quantum circuits\n",
    "    circuits = [ansatz(diagram) for diagram in diagrams]\n",
    "\n",
    "    # apply NOT box to circuits\n",
    "    for i, circuit in enumerate(circuits):\n",
    "        if data[i].find(\" not \") != -1:\n",
    "            if (not_representation == \"ZX\"):\n",
    "                circuits[i] = circuit >> Z >> X\n",
    "            else:\n",
    "                circuits[i] = circuit >> X\n",
    "    \n",
    "    if return_valids_mask:\n",
    "        return data, diagrams, circuits, valids_mask\n",
    "    else:\n",
    "        return data, diagrams, circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c474ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "working_dir = \"../data/experiment_results/\"\n",
    "experiment_book = []\n",
    "\n",
    "for experiment_name in os.listdir(working_dir):\n",
    "    experiment_dir = working_dir+experiment_name+\"/\"\n",
    "    if os.path.isdir(experiment_dir):\n",
    "        if \"fit_time.txt\" in os.listdir(experiment_dir):\n",
    "            experiment_dict = {\"name\": experiment_name}\n",
    "\n",
    "            with open(experiment_dir+\"params.txt\", \"r\") as f:\n",
    "                content = f.read().replace(\"\\'\", \"\\\"\")\n",
    "                params_dict = json.loads(content)\n",
    "                f.close()\n",
    "            \n",
    "            experiment_dict[\"params\"] = params_dict\n",
    "\n",
    "            if \"200iter\" in experiment_name:\n",
    "                experiment_dict[\"iter\"] = 200\n",
    "            else:\n",
    "                experiment_dict[\"iter\"] = 130\n",
    "            \n",
    "            if \"2layer\" in experiment_name:\n",
    "                experiment_dict[\"n_layers\"] = 2\n",
    "            elif \"3layer\" in experiment_name:\n",
    "                experiment_dict[\"n_layers\"] = 3\n",
    "            else:\n",
    "                experiment_dict[\"n_layers\"] = 1\n",
    "            \n",
    "            if \"generalQC\" in experiment_name:\n",
    "                is_v2 = False\n",
    "                if \"V2\" in experiment_name:\n",
    "                    experiment_dict[\"ansatz\"] = \"GeneralQCAnsatzV2\"\n",
    "                    \n",
    "                    if \"H_CRx\" in experiment_name:\n",
    "                        experiment_dict[\"block_layer\"] = \"HCRxLayerV2\"\n",
    "                    elif \"H_CRz\" in experiment_name:\n",
    "                        experiment_dict[\"block_layer\"] = \"HCRzLayerV2\"\n",
    "                else:\n",
    "                    experiment_dict[\"ansatz\"] = \"GeneralQCAnsatz\"\n",
    "\n",
    "                    if \"H_CRx\" in experiment_name:\n",
    "                        experiment_dict[\"block_layer\"] = \"HCRxLayer\"\n",
    "                    elif \"H_CRz\" in experiment_name:\n",
    "                        experiment_dict[\"block_layer\"] = \"HCRzLayer\"\n",
    "            \n",
    "            if \"iqp\" in experiment_name:\n",
    "                experiment_dict[\"ansatz\"] = \"IQPAnsatz\"\n",
    "              \n",
    "            if \"simple_sa\" in experiment_name:\n",
    "                experiment_dict[\"ansatz\"] = \"SimpleSAAnsatz\"\n",
    "\n",
    "                if \"with_nouns\" in experiment_name:\n",
    "                    experiment_dict[\"n_single_qubit_params\"] = 3\n",
    "                else:\n",
    "                    experiment_dict[\"n_single_qubit_params\"] = 0\n",
    "            \n",
    "            if \"sim15\" in experiment_name:\n",
    "                experiment_dict[\"ansatz\"] = \"Sim15Ansatz\"\n",
    "            if \"sim15_sa\" in experiment_name:\n",
    "                experiment_dict[\"ansatz\"] = \"Sim15SAAnsatz\"\n",
    "        \n",
    "            experiment_book.append(experiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25feee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import AerBackend\n",
    "\n",
    "backend = AerBackend()\n",
    "\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'n_shots': 8192  # maximum recommended shots, reduces sampling error\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6886a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy.quantum import Circuit, Id, Measure\n",
    "\n",
    "def randint(rng, low=-1 << 63, high=1 << 63-1):\n",
    "    return rng.integers(low, high)\n",
    "\n",
    "def normalise(predictions):\n",
    "    # apply smoothing to predictions\n",
    "    predictions = np.abs(predictions) + 1e-9\n",
    "    return predictions / predictions.sum()\n",
    "\n",
    "def make_pred_fn(circuits, parameters, rng):\n",
    "    measured_circuits = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuits]\n",
    "    circuit_fns = [c.lambdify(*parameters) for c in measured_circuits]\n",
    "\n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c_fn(*params) for c_fn in circuit_fns),\n",
    "                               **backend_config, seed=randint(rng))\n",
    "        return np.array([normalise(output.array) for output in outputs])\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "519f3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import AtomicType, IQPAnsatz, Sim15Ansatz\n",
    "from sympy import default_sort_key\n",
    "\n",
    "\n",
    "def decapitate_circuit(circuit):\n",
    "    from discopy import Bra, Measure\n",
    "\n",
    "    cutoff = None\n",
    "\n",
    "    for i, box in enumerate(circuit.boxes):\n",
    "        if box in [Bra, Measure, Bra(0), Bra(0, 0)]:\n",
    "            cutoff = i\n",
    "            break\n",
    "    \n",
    "    return circuit[:i]\n",
    "\n",
    "def build_circuit_library(experiment_dict, data_src, targets_src):\n",
    "    name = experiment_dict[\"name\"]\n",
    "    params = experiment_dict[\"params\"]\n",
    "    ansatz_name = experiment_dict[\"ansatz\"]\n",
    "    n_layers = experiment_dict[\"n_layers\"]\n",
    "    spsa_n_iter = experiment_dict[\"iter\"]\n",
    "\n",
    "    if ansatz_name in [\"SimpleSAAnsatz\"]:\n",
    "        n_single_qubit_params = experiment_dict[\"n_single_qubit_params\"]\n",
    "    if ansatz_name in [\"GeneralQCAnsatz\", \"GeneralQCAnsatzV2\"]:\n",
    "        block_layer_name = experiment_dict[\"block_layer\"]\n",
    "    \n",
    "    parameters = list(params.keys())\n",
    "    param_vals = [params[key] for key in parameters]\n",
    "\n",
    "    # build ansatz\n",
    "    N = AtomicType.NOUN\n",
    "    S = AtomicType.SENTENCE\n",
    "\n",
    "    if ansatz_name == \"IQPAnsatz\":\n",
    "        ansatz = IQPAnsatz({N: 1, S: 1}, n_layers=n_layers)\n",
    "    elif ansatz_name == \"SimpleSAAnsatz\":\n",
    "        ansatz = SimpleSAAnsatz({N: 1, S: 1}, n_layers=n_layers, n_single_qubit_params=n_single_qubit_params)\n",
    "    elif ansatz_name == \"Sim15Ansatz\":\n",
    "        ansatz = Sim15Ansatz({N: 1, S: 1}, n_layers=n_layers)\n",
    "    elif ansatz_name == \"Sim15SAAnsatz\":\n",
    "        ansatz = Sim15SAAnsatz({N: 1, S: 1}, n_layers=n_layers)\n",
    "    elif ansatz_name == \"GeneralQCAnsatz\":\n",
    "        if block_layer_name == \"HCRxLayer\":\n",
    "            block_layer = HCRxLayer\n",
    "        elif block_layer_name == \"HCRzLayer\":\n",
    "            block_layer = HCRzLayer\n",
    "        \n",
    "        ansatz = GeneralQCAnsatz({N: 1, S: 1}, n_layers=n_layers, block_layer=block_layer)\n",
    "    elif ansatz_name == \"GeneralQCAnsatzV2\":\n",
    "        if block_layer_name == \"HCRxLayerV2\":\n",
    "            block_layer = HCRxLayerV2\n",
    "        elif block_layer_name == \"HCRzLayerV2\":\n",
    "            block_layer = HCRzLayerV2\n",
    "        \n",
    "        ansatz = GeneralQCAnsatzV2({N: 1, S: 1}, n_layers=n_layers, block_layer=block_layer)\n",
    "    \n",
    "    data, diagrams, circuits, valids_mask = sentences_to_circuits(data_src, ansatz)\n",
    "    targets = [target for i, target in enumerate(targets_src) if valids_mask[i]]\n",
    "\n",
    "    circuit_heads = []\n",
    "\n",
    "    # instantiate complete circuits\n",
    "\n",
    "    SEED = 0\n",
    "    rng = np.random.default_rng(SEED)\n",
    "\n",
    "    use_parameters = sorted({s for circ in circuits for s in circ.free_symbols},key=default_sort_key)\n",
    "    use_param_strs = [str(param_sym) for param_sym in use_parameters]\n",
    "    use_param_vals = [val for i, val in enumerate(param_vals) if parameters[i] in use_param_strs]\n",
    "\n",
    "    measured_circuits = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuits]\n",
    "    circuit_fns = [c.lambdify(*use_parameters) for c in measured_circuits]\n",
    "    instantiated_circuits = [c_fn(*use_param_vals) for c_fn in circuit_fns]\n",
    "\n",
    "    outputs = Circuit.eval(*instantiated_circuits, **backend_config, seed=randint(rng))\n",
    "    res = np.array([normalise(output.array) for output in outputs])\n",
    "\n",
    "    circuit_heads = [decapitate_circuit(c) for c in circuits]\n",
    "\n",
    "    # measured_circuit_heads = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuit_heads]\n",
    "    circuit_head_fns = [c.lambdify(*use_parameters) for c in circuit_heads]\n",
    "    instantiated_circuit_heads = [c_fn(*use_param_vals) for c_fn in circuit_head_fns]\n",
    "\n",
    "    return data, targets, parameters, param_vals, diagrams, ansatz, circuits, instantiated_circuits, circuit_heads, instantiated_circuit_heads, outputs, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d122ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computational_bases(n_qubits):\n",
    "    return np.array([[int(j==i) for j in range(2**n_qubits)] for i in range(2**n_qubits)], dtype='cfloat')\n",
    "\n",
    "def tensor_prod(v2, v1):\n",
    "    return np.tensordot(v1, v2, axes=0).flatten()\n",
    "\n",
    "def bloch_bases(n_qubits, n_alpha, n_beta):\n",
    "    z_1 = computational_bases(1)\n",
    "    b_plus = lambda alpha, beta: np.cos(alpha/2)*z_1[0] + np.sin(alpha/2)*np.exp((0+1j)*beta)*z_1[1]\n",
    "    b_minus = lambda alpha, beta: np.sin(alpha/2)*z_1[0] - np.cos(alpha/2)*np.exp((0+1j)*beta)*z_1[1]\n",
    "\n",
    "    alpha_dom = np.linspace(0, np.pi, n_alpha)\n",
    "    beta_dom = np.linspace(0, 2*np.pi, n_beta)\n",
    "\n",
    "    def b_bases_paramx(thetas):\n",
    "        b_bases = computational_bases(0)\n",
    "\n",
    "        for i in range(n_qubits):\n",
    "            b_pluses = [tensor_prod(b_plus(thetas[2*i], thetas[2*i+1]), b_basis) for b_basis in b_bases]\n",
    "            b_minuses = [tensor_prod(b_minus(thetas[2*i], thetas[2*i+1]), b_basis) for b_basis in b_bases]\n",
    "\n",
    "            b_bases = np.vstack([b_pluses, b_minuses])\n",
    "        \n",
    "        return b_bases\n",
    "    \n",
    "    bloch_space = [None for _ in range((n_alpha*n_beta)**(n_qubits))]\n",
    "\n",
    "    def recursive_search(level, curr_idx=[], curr_thetas=[]):\n",
    "        for i, alpha0 in enumerate(alpha_dom):\n",
    "            for j, beta0 in enumerate(beta_dom):\n",
    "                if level == 1:\n",
    "                    index = 0\n",
    "                    for a_i, b_j in curr_idx+[[i, j]]:\n",
    "                        index = index*n_alpha*n_beta+a_i*n_alpha+b_j\n",
    "                    \n",
    "                    bloch_space[index] = b_bases_paramx(curr_thetas+[alpha0, beta0])\n",
    "                else:\n",
    "                    recursive_search(level-1, curr_idx+[[i, j]], curr_thetas+[alpha0, beta0])\n",
    "\n",
    "    recursive_search(n_qubits)\n",
    "\n",
    "    return bloch_space\n",
    "\n",
    "def trace(mat):\n",
    "    return np.cfloat(sum([mat[i][i] for i in range(len(mat))]))\n",
    "\n",
    "def abstrace(mat):\n",
    "    return float(sum([np.absolute(mat[i][i]) for i in range(len(mat))]))\n",
    "\n",
    "def KD(a, b, rho):\n",
    "    Pi_a = np.outer(a, np.conjugate(a))\n",
    "    Pi_b = np.outer(b, np.conjugate(b))\n",
    "    return trace(np.matmul(Pi_b, np.matmul(Pi_a, rho)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46b65ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, execute\n",
    "from qiskit import Aer\n",
    "\n",
    "def build_clifford_set(n_qubits, cliffords=[]):\n",
    "    single_qubit_cliffords = [\n",
    "        '',\n",
    "        'H', 'S',\n",
    "        'HS', 'SH', 'SS',\n",
    "        'HSH', 'HSS', 'SHS', 'SSH', 'SSS',\n",
    "        'HSHS', 'HSSH', 'HSSS', 'SHSS', 'SSHS',\n",
    "        'HSHSS', 'HSSHS', 'SHSSH', 'SHSSS', 'SSHSS',\n",
    "        'HSHSSH', 'HSHSSS', 'HSSHSS'\n",
    "    ]\n",
    "\n",
    "    if n_qubits == 0:\n",
    "        return cliffords\n",
    "    else:\n",
    "        if len(cliffords) == 0:\n",
    "            return build_clifford_set(n_qubits-1, [[sc] for sc in single_qubit_cliffords])\n",
    "        else:\n",
    "            temp_cliffords = [[c+[sc] for sc in single_qubit_cliffords] for c in cliffords]\n",
    "            new_cliffords = [item for sublist in temp_cliffords for item in sublist]\n",
    "\n",
    "            return build_clifford_set(n_qubits-1, new_cliffords)\n",
    "\n",
    "def build_clifford_states(n_qubits):\n",
    "    backend = Aer.get_backend('unitary_simulator')\n",
    "\n",
    "    multi_qubit_cliffords = build_clifford_set(n_qubits)\n",
    "    mqc_svs = [clifford_str_to_sv(c, backend) for c in multi_qubit_cliffords]\n",
    "\n",
    "    return mqc_svs\n",
    "\n",
    "def clifford_str_to_sv(clifford_str, backend):\n",
    "    n_qubits = len(clifford_str)\n",
    "\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "\n",
    "    for i in range(n_qubits):\n",
    "        for j, gate in enumerate(clifford_str[i]):\n",
    "            if gate == \"H\":\n",
    "                qc.h(n_qubits-i-1)\n",
    "            if gate == \"S\":\n",
    "                qc.s(n_qubits-i-1)\n",
    "\n",
    "    job = execute(qc, backend, shots=8192)\n",
    "    job_result = job.result()\n",
    "\n",
    "    return job_result.get_unitary(qc).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc0503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_qubit_cliffords = {}\n",
    "\n",
    "for n_qubits in [2, 3, 4]:\n",
    "    multi_qubit_cliffords[n_qubits] = build_clifford_states(n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90479e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/datasets/mqc_vals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(multi_qubit_cliffords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43d363d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_bases = {2: computational_bases(2), 3: computational_bases(3), 4: computational_bases(4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a00c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tagging sentences:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing tagged sentences:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parse trees to diagrams:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRx 4 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 576/576 [00:00<00:00, 1506.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRx 8 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 13824/13824 [00:07<00:00, 1855.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRx 16 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 331776/331776 [1:22:32<00:00, 67.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRx [0.687845959763836, 0.24793740384491364, 0.6831960802304892, 0.6564152863238435, 0.687845959763836, 0.5955060763670468, 0.7018410854736957, 0.24793740384491364, 0.24793740384491364, 0.7018410854736957, 0.6564152863238435, 0.6831960802304892, 0.687845959763836, 0.647626265263509, 0.8109381483012108, 0.24793740384491364, 0.6831960802304892, 1.4041119656323875, 1.248527418666565, 0.9014487254471084, 2.583002446458354, 2.358401840611941, 2.1832291814849567, 1.884071296359245, 2.583966856062038, 2.295594490549921, 2.3597567454047197, 2.3795040484185983, 2.1752299650364586, 2.3258414745411486, 1.9605692775575447, 2.528120185827682, 2.0241670110497507, 2.2929183542225546, 2.0612025584058196, 2.3536947203505174, 1.6506856920925879, 1.3771020961334617, 2.5234477407598, 2.1111818336971013, 2.167993292801687, 2.1776392849526682, 1.6855476607017954, 2.211944652891472, 2.4870613094476886, 2.480158815941254, 1.6292747542256991, 2.01547497497809, 1.884071296359245, 2.5234477407598, 2.1111818336971013, 2.092146280004987, 2.0528063743469485, 2.3597567454047197, 2.0612025584058196, 2.3536947203505174, 2.0993225597911374, 1.8498029071782012, 2.3740458847905916, 1.9850405163048424] 1.6673808176165668\n",
      "4960.014661550522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tagging sentences:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing tagged sentences:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parse trees to diagrams:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRx_V2 4 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 576/576 [00:00<00:00, 1608.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRx_V2 8 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 13824/13824 [00:06<00:00, 2081.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRx_V2 16 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 331776/331776 [1:24:48<00:00, 65.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRx_V2 [0.8286772663826291, 0.6953426007137198, 0.7736508815077915, 0.5458770197534281, 0.8286772663826291, 0.9090985449111113, 0.7178035148511863, 0.6953426007137198, 0.6953426007137198, 0.7178035148511863, 0.5458770197534281, 0.7736508815077915, 0.8286772663826291, 0.7657894834878624, 0.5314775965032339, 0.6953426007137198, 0.7736508815077915, 1.3899485493308534, 1.1972124243344513, 1.3703261917342802, 1.693308095172916, 1.8601130258129235, 2.3356075347727194, 2.1025093397919217, 1.6133754874371473, 2.2143125000173263, 1.842929638064346, 1.8467247842979895, 1.797575410454058, 1.8883650083399628, 2.1509547804471056, 2.3306386747283474, 2.1512531588543196, 2.1412044763758327, 2.4307683015629293, 2.3463557378724245, 1.9508054478952745, 2.252184336769371, 1.6189314631804612, 2.1424103232627862, 1.8637588158259963, 2.166007056950744, 1.877404434782428, 1.9543427382145317, 1.44289097500453, 2.2651323647414143, 2.2819634688365387, 1.4310899487993882, 2.1025093397919217, 1.6189314631804612, 2.1424103232627862, 1.8314921599017255, 2.4565226630162584, 1.842929638064346, 2.4307683015629293, 2.3463557378724245, 2.15974902633403, 2.0448553827889886, 2.042676033602241, 2.1876082140217683] 1.624654905295046\n",
      "5095.651408910751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tagging sentences:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing tagged sentences:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parse trees to diagrams:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generalQC_H_CRz 4 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████▍                                                                            | 126/576 [00:00<00:00, 1255.34it/s]"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "coherence_dict = {}\n",
    "\n",
    "for k, experiment_dict in enumerate(experiment_book):\n",
    "    if experiment_dict[\"name\"] in coherence_dict:\n",
    "        experiment_book[k][\"NCLs\"] = np.array(coherence_dict[experiment_dict[\"name\"]][\"ncls\"])\n",
    "        experiment_book[k][\"coherence\"] = coherence_dict[experiment_dict[\"name\"]][\"avg\"]\n",
    "        continue\n",
    "    \n",
    "    data, targets, parameters, param_vals, diagrams, ansatz, circuits, instantiated_circuits, circuit_heads, instantiated_circuit_heads, outputs, res = build_circuit_library(experiment_dict, test_data_src, test_targets_src)\n",
    "    sv_data = [c.to_tk().get_statevector() for c in instantiated_circuit_heads]\n",
    "\n",
    "    NCLs = [None for _ in sv_data]\n",
    "\n",
    "    sv_lengths = [len(sv) for sv in sv_data]\n",
    "    sv_sorted = [x for _, x in sorted(zip(sv_lengths, sv_data), key=lambda pair: pair[0])]\n",
    "    sv_lengths_sorted = [x for x, _ in sorted(zip(sv_lengths, sv_data), key=lambda pair: pair[0])]\n",
    "\n",
    "    dim = sv_lengths_sorted[0]\n",
    "    i = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while i < len(sv_data):\n",
    "        i0 = i\n",
    "        while i < len(sv_data) and sv_lengths_sorted[i] == dim:\n",
    "            i += 1\n",
    "        \n",
    "        sv_use = sv_sorted[i0:i]\n",
    "        print(experiment_dict[\"name\"], dim, i)\n",
    "\n",
    "        n_qubits = int(math.log2(dim))\n",
    "\n",
    "        if n_qubits not in multi_qubit_cliffords:\n",
    "            multi_qubit_cliffords[n_qubits] = build_clifford_states(n_qubits)\n",
    "        if n_qubits not in z_bases:\n",
    "            z_bases[n_qubits] = computational_bases(n_qubits)\n",
    "        \n",
    "        rhos = [np.outer(sv, sv.conjugate()) for sv in sv_use]\n",
    "\n",
    "        y_max = np.array([-1 for _ in sv_use], dtype='float')\n",
    "\n",
    "        for haar_basis in tqdm(multi_qubit_cliffords[n_qubits]):\n",
    "            kd_sums = np.array([-1 for _ in sv_use], dtype='float')\n",
    "            \n",
    "            for hs in haar_basis:\n",
    "                Pi_b = np.outer(hs, hs.conjugate())\n",
    "                kd_sum = np.array([abstrace(np.matmul(Pi_b, rho)) for rho in rhos], dtype='float')\n",
    "                kd_sums += kd_sum\n",
    "                \n",
    "            y_max = y_max*(y_max > kd_sums) + kd_sums*(kd_sums >= y_max)\n",
    "\n",
    "        for j in range(i0, i):\n",
    "            NCLs[j] = y_max[j-i0]\n",
    "        if i < len(sv_data):\n",
    "            dim = sv_lengths_sorted[i]\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    experiment_book[k][\"NCLs\"] = NCLs\n",
    "    experiment_book[k][\"coherence\"] = sum(NCLs)/len(NCLs)\n",
    "    coherence_dict[experiment_dict[\"name\"]] = {\"name\": NCLs, \"avg\": sum(NCLs)/len(NCLs)}\n",
    "\n",
    "    print(experiment_dict[\"name\"], NCLs, sum(NCLs)/len(NCLs))\n",
    "    print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66cc40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
