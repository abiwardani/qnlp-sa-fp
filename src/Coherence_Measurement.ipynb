{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6ddab11",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Parameters\n",
    "\n",
    "# Experiment conditions\n",
    "use_all_rewriter_rules = True\n",
    "convert_bigraph = True\n",
    "not_representation = \"X\"\n",
    "not_placement = \"end\"\n",
    "gate_layers = [\"H\", \"Rx\"]\n",
    "var_layers = 1\n",
    "parameterize_nouns = False\n",
    "# independent_sublayer = False\n",
    "\n",
    "# load params\n",
    "train_params = True\n",
    "load_params = True\n",
    "# param_vals = [0.6931585473443279, 1.0462424956825283, 1.234537983904686, -2.90716906835752, 1.5753587952252757, -2.4968837592255424, 1.6118961289272027, -1.016327328767516, -0.3142432619217712, 1.208915586540799, -1.1801888411140051, -0.4286556908790561, 3.3779520000989214, 0.04286513605390508, 0.5295399156230165, -1.7699845136573933, 0.5233673239374572, -1.748569530235187, -0.26823991786760143, 1.813789372735753, -2.9079130258111228, -0.6129166776514257, 0.3401131125827421, -0.4365025178512618, 1.008439272978763, 0.06192528487377933, 1.6121247434136865, 3.3613679248015504, 4.1316674342901845, 0.8303800120316661, -1.227825304579597, -1.8130593574910823, 0.1848756781930945, -0.676881418623572, 2.591255835558515, 1.6673593894980614, 1.6540892586338571, 1.6143400480675385, 0.23932506846152854, 1.5181285887362506, 0.13241105800686212, 3.8061670131492367, 0.5807166437788316, 1.5116799923186133, 1.5599307705774368, 0.29362851954048996, 0.19967375719855993, 1.914813488873402, 2.7644195885210587, 0.37942837286458875, 2.3383678677227993, -0.5843868818793704, 3.921194364357892, 1.4174799045629805, 2.741638785064822, -0.6304530862551285, -1.8933985338953436, 1.5624277556723982, -1.1677654133728248, -0.8250732415577517, 1.7230226879389658, -0.8418763059243636, 0.9691454037142504, 0.7252400407386729, -1.9797782989274328, 2.2739476528314704, 0.4612678359290186, 2.2453750405051833, 1.2218764611893127, -1.4926462511306318, 1.5083681953206398, -0.6209409896223363, -0.8575621399562154, -1.1360971020856898, -0.32413810704072976, 2.317045883444611, 0.052405537301035005]\n",
    "# params_saved = {'I__n_0': 1.3926202901320248, 'I__n_1': 0.008448820382520305, 'I__n_2': -0.6385783774702594, 'aw__n.r@s_0': 0.004878974097219957, 'aw__n@n.l_0': -1.710437394121971, 'bad__n.r@s_0': -2.0120646244526674, 'bad__n@n.l_0': -0.33328110433838587, 'bland__n.r@s_0': -1.8011492489090937, 'bland__n@n.l_0': -0.23301002690494765, 'cook__n.r@s@n.l_0': 2.666641605278804, 'cook__n.r@s@n.l_1': 0.35782850997078663, 'delici__n.r@s_0': -0.6784353476839611, 'delici__n@n.l_0': 2.5048532581915994, 'dislik__n.r@s@n.l_0': 1.264688638132907, 'dislik__n.r@s@n.l_1': 2.9058201511277773, 'fast__n.r@s_0': 1.5228059027468268, 'fast__n@n.l_0': 1.4318617692717328, 'food__n_0': 0.9510109180885518, 'food__n_1': 1.983545943335132, 'food__n_2': 0.31422754989262236, 'good__n.r@s_0': -0.37898061288101936, 'good__n@n.l_0': 0.3417258364922475, 'great__n.r@s_0': 0.32023762451562343, 'great__n@n.l_0': 1.9344786256084243, 'had__n.r@s@n.l_0': 0.9175005505289897, 'had__n.r@s@n.l_1': -1.126491771734188, 'hate__n.r@s@n.l_0': 1.0178843262642405, 'hate__n.r@s@n.l_1': -0.8544213946932742, 'impecc__n.r@s_0': 0.8774940821788493, 'impecc__n@n.l_0': 0.28533233081922516, 'like__n.r@s@n.l_0': 0.5238711836690633, 'like__n.r@s@n.l_1': -0.0248482491004431, 'love__n.r@s@n.l_0': -1.0716522290529822, 'love__n.r@s@n.l_1': 0.4674574117431039, 'meal__n_0': -0.2913227630628624, 'meal__n_1': -0.7824158049259571, 'meal__n_2': 2.364685233940882, 'nice__n.r@s_0': -0.31906215984000647, 'nice__n@n.l_0': -2.087345064482271, 'restaur__n_0': 1.9567881690203595, 'restaur__n_1': 0.35319298096689367, 'restaur__n_2': -0.5953604557383299, 'rude__n.r@s_0': 2.1631540155864895, 'rude__n@n.l_0': -0.9753409914505806, 'servic__n_0': -2.7047864895209357, 'servic__n_1': 1.2351321590961786, 'servic__n_2': -1.5851261977616085, 'show__n.r@s@n.l_0': -0.6393012792612347, 'show__n.r@s@n.l_1': 1.7857303585103954, 'slow__n.r@s_0': 0.5156333465906835, 'slow__n@n.l_0': 1.0425765284092643, 'staff__n_0': 0.08543447326700565, 'staff__n_1': -2.068154595353262, 'staff__n_2': 0.019379227469981927, 'tasti__n.r@s_0': 1.2246133069435021, 'tasti__n@n.l_0': 1.9668107229444722, 'terribl__n.r@s_0': -0.3440262636975905, 'terribl__n@n.l_0': 2.1861199395142688, 'unappet__n.r@s_0': 1.440589048292482, 'unappet__n@n.l_0': -0.31598863954665035, 'wa__s@s.l_0': -1.0244128683696618}\n",
    "spsa_a = 0.2\n",
    "spsa_c = 0.06\n",
    "spsa_n_iter = 0\n",
    "k0 = 0\n",
    "\n",
    "# SVM type\n",
    "kernel = 'rbf'\n",
    "default_svm = True\n",
    "optimize_svm = False\n",
    "\n",
    "# Experiment metadata\n",
    "experiment_name = \"misc\"\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "if (experiment_name == \"\"):\n",
    "    experiment_name = \"misc\"\n",
    "\n",
    "path = '../data/experiment_results/journal/generalQC/'+experiment_name\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except:\n",
    "    print(\"experiment folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fba1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_data(filename):\n",
    "    labels, sentences = [], []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            labels.append([1, 0] if line[0] == '1' else [0, 1])\n",
    "            sentences.append(line[1:].strip())\n",
    "    return np.array(labels), sentences\n",
    "\n",
    "test_targets_src, test_data_src = read_data('../data/datasets/restaurant_v5_test.txt')\n",
    "dev_targets_src, dev_data_src = read_data('../data/datasets/restaurant_v5_dev.txt')\n",
    "train_targets_src, train_data_src = read_data('../data/datasets/restaurant_v5_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for converting to bigraph\n",
    "\n",
    "from discopy.rigid import Id as RigidId\n",
    "\n",
    "def checkTrailingCups(diagram):\n",
    "    scanWords = True\n",
    "    \n",
    "    for box in diagram.boxes:\n",
    "        if not box.dom and not scanWords:\n",
    "            return False\n",
    "        else:\n",
    "            scanWords = scanWords and not box.dom\n",
    "    \n",
    "    return True\n",
    "\n",
    "def convertToTrailingCups(diagram):\n",
    "    if (checkTrailingCups(diagram)):\n",
    "        return diagram\n",
    "\n",
    "    words = []\n",
    "    cups = []\n",
    "    \n",
    "    for box in diagram.boxes:\n",
    "        if not box.dom:\n",
    "            words = words + [box]\n",
    "        else:\n",
    "            cups = [box] + cups\n",
    "    \n",
    "    new_diag = words[0]\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if i != 0:\n",
    "            new_diag = new_diag >> RigidId(new_diag.cod) @ word\n",
    "    \n",
    "    for i, cup in enumerate(cups):\n",
    "        if i != len(cups)-1:\n",
    "            new_diag = new_diag >> RigidId(new_diag.cod[:-2]) @ cup\n",
    "        else:\n",
    "            new_diag = new_diag >> cup @ RigidId(new_diag.cod[2:])\n",
    "    \n",
    "    return new_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion for stemming and lemmatization of tokens\n",
    "\n",
    "def to_word_tokens(data):\n",
    "    return [word_tokenize(record) for record in data]\n",
    "\n",
    "def build_stem_dictionary(data):\n",
    "    port = PorterStemmer()\n",
    "    wnet = WordNetLemmatizer()\n",
    "    \n",
    "    mapping = {}\n",
    "    \n",
    "    data_as_tokens = to_word_tokens(data)\n",
    "    \n",
    "    for words in data_as_tokens:\n",
    "        for word in words:\n",
    "            if word not in mapping:\n",
    "                stemmed_word = port.stem(word)\n",
    "                lemmatized_word = wnet.lemmatize(stemmed_word)\n",
    "                \n",
    "                mapping[word] = lemmatized_word\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6454a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for stemming and lemmatization of diagram boxes\n",
    "\n",
    "from lambeq.rewrite import RewriteRule\n",
    "\n",
    "class StemRewriteRule(RewriteRule):\n",
    "    def __init__(self, data):\n",
    "        self.mapping = build_stem_dictionary(data)\n",
    "    \n",
    "    def matches(self, box):\n",
    "        return box.name in self.mapping\n",
    "\n",
    "    def rewrite(self, box):\n",
    "        new_name = self.mapping[box.name]\n",
    "        return type(box)(name=new_name, dom=box.dom, cod=box.cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq.ansatz import CircuitAnsatz\n",
    "from abc import abstractmethod\n",
    "# from collections.abc import Mapping\n",
    "from itertools import cycle\n",
    "from typing import Callable, Optional, Tuple, Mapping\n",
    "from discopy.quantum.circuit import (Circuit, Functor, Id, qubit)\n",
    "from discopy.quantum.gates import Bra, Ket, Controlled, Rotation\n",
    "from discopy.quantum.gates import H, X, Y, Z, Rx, Ry, Rz\n",
    "from discopy.rigid import Box, Diagram, Ty\n",
    "from discopy.tensor import Dim, Tensor\n",
    "import numpy as np\n",
    "from sympy import Symbol, symbols\n",
    "\n",
    "class GeneralQCLayer(Circuit):\n",
    "    \n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import Rx, Rz\n",
    "\n",
    "        if len(self.gate_layers) != 2:\n",
    "            raise ValueError(\"Expected gate_layers as tuple of strings\")\n",
    "        \n",
    "        g1, g2 = self.gate_layers\n",
    "\n",
    "        if (g1 == None) or (g2 == None):\n",
    "            raise ValueError(\"gate_layers must be in discopy.quantum.gates\")\n",
    "        # if not (abs(self.r1) == 1 and abs(self.r2) == 1) and ((abs(self.r1) == 1 or abs(self.r2) == 1) and (self.r2 % self.r1 == 0 or self.r1 % self.r2 == 0)) or (n_qubits % self.r1 == 0 and self.r1 != 1) or (n_qubits % self.r2 == 0 and self.r2 != 1):\n",
    "        #     raise ValueError(\"n_qubits, r1, and r2 must be co-prime\")\n",
    "\n",
    "        params_shape = np.shape(params)\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            if len(params) == 0:\n",
    "                circuit = Id(1)\n",
    "            else:\n",
    "                circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "        elif (len(params_shape) != 2):\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits))\n",
    "        else:\n",
    "            g1_thetas = 0\n",
    "            g2_thetas = 0\n",
    "\n",
    "            if g1.free_symbols != {}:\n",
    "                # g1 is fixed\n",
    "                g1_thetas = n_qubits\n",
    "            if g2.free_symbols != {}:\n",
    "                g2_thetas = n_qubits\n",
    "\n",
    "            if self.reuse_params:\n",
    "                self.k = 1\n",
    "            else:\n",
    "                self.k = 2\n",
    "            \n",
    "            n_thetas = self.k*(g1_thetas + g2_thetas)\n",
    "\n",
    "            if (params_shape[1] != n_thetas):\n",
    "                raise ValueError(\n",
    "                    \"Expected component params with length {}\".format(n_thetas))\n",
    "\n",
    "            # ANSATZ ALGORITHM\n",
    "            circuit = Id(n_qubits)\n",
    "            \n",
    "            # for {theta} in labelled params\n",
    "            for thetas in params:\n",
    "                \n",
    "                # sublayer 1 non-entangling block\n",
    "                if g1_thetas == 0:\n",
    "                    # if g1 is fixed\n",
    "                    sublayer1 = Id().tensor(*([g1 for _ in range(n_qubits)]))\n",
    "                else:\n",
    "                    # if g1 is trainable\n",
    "                    sublayer1 = Id().tensor(*([g1(theta) for theta in thetas[:g1_thetas]]))\n",
    "                \n",
    "                # sublayer 1 entangled block\n",
    "                ctrl = 0\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    # shift target := control - r1\n",
    "                    tgt = (ctrl - self.r1) % n_qubits\n",
    "                    \n",
    "                    if g2_thetas == 0:\n",
    "                        sublayer1 = sublayer1._apply_controlled(g2, ctrl, tgt)\n",
    "                        # sublayer1 = sublayer1.CX(ctrl, tgt)\n",
    "                    else:\n",
    "                        sublayer1 = sublayer1._apply_controlled(g2(thetas[g1_thetas + i]), ctrl, tgt)\n",
    "                        # sublayer1 = sublayer1.CRx(thetas[g1_thetas + i], ctrl, tgt)\n",
    "                    \n",
    "                    ctrl = tgt\n",
    "                \n",
    "                # sublayer 2 non-entangling block\n",
    "                if g1_thetas == 0:\n",
    "                    sublayer2 = Id().tensor(*([g1 for _ in range(n_qubits)]))\n",
    "                else:\n",
    "                    if self.reuse_params:\n",
    "                        sublayer2 = Id().tensor(*([g1(theta) for theta in thetas[:g1_thetas]]))\n",
    "                    else:\n",
    "                        sublayer2 = Id().tensor(*([g1(theta) for theta in thetas[g1_thetas+g2_thetas:2*g1_thetas+g2_thetas]]))\n",
    "                \n",
    "                # sublayer 2 entangled block\n",
    "                ctrl = 0\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    # shift target := control - r2\n",
    "                    tgt = (ctrl - self.r2) % n_qubits\n",
    "\n",
    "                    if g2_thetas == 0:\n",
    "                        sublayer2 = sublayer2._apply_controlled(g2, ctrl, tgt)\n",
    "                        # sublayer2 = sublayer2.CX(ctrl, tgt)\n",
    "                    else:\n",
    "                        if self.reuse_params:\n",
    "                            sublayer2 = sublayer2._apply_controlled(g2(thetas[g1_thetas + i]), ctrl, tgt)\n",
    "                        else:\n",
    "                            sublayer2 = sublayer2._apply_controlled(g2(thetas[2*g1_thetas+g2_thetas+i]), ctrl, tgt)\n",
    "                            # sublayer2 = sublayer2.CRx(thetas[2*g1_thetas+g2_thetas+i], ctrl, tgt)\n",
    "                    \n",
    "                    ctrl = tgt\n",
    "            \n",
    "                # compose circuit\n",
    "                circuit >>= sublayer1 >> sublayer2\n",
    "            \n",
    "        super().__init__(\n",
    "            circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class GeneralQCAnsatz(CircuitAnsatz):\n",
    "    def __init__(self, ob_map: Mapping[Ty, int], n_layers: int, n_single_qubit_params: int = 0, gate_config = {\"gate_layers\": [H, Rx], \"var_layers\": 1}, r = (1, 3), reuse_params=True, discard: bool = False) -> None:\n",
    "        self.gate_config = gate_config\n",
    "        self.reuse_params = reuse_params\n",
    "        self.r = r\n",
    "        \n",
    "        class GeneralQCInterface(GeneralQCLayer):\n",
    "            \"\"\" Interface for GeneralQCLayer \"\"\"\n",
    "\n",
    "            def strToGate(gateStr):\n",
    "                if gateStr == \"H\":\n",
    "                    return H\n",
    "                if gateStr == \"X\":\n",
    "                    return X\n",
    "                if gateStr == \"Y\":\n",
    "                    return Y\n",
    "                if gateStr == \"Z\":\n",
    "                    return Z\n",
    "                if gateStr == \"Rx\":\n",
    "                    return Rx\n",
    "                if gateStr == \"Ry\":\n",
    "                    return Ry\n",
    "                if gateStr == \"Rz\":\n",
    "                    return Rz\n",
    "                \n",
    "                return Id(1)\n",
    "            \n",
    "            assert(len(self.gate_config[\"gate_layers\"]) == 2)\n",
    "\n",
    "            g1, g2 = self.gate_config[\"gate_layers\"]\n",
    "\n",
    "            if isinstance(g1, str):\n",
    "                g1 = strToGate(g1)\n",
    "            if isinstance(g2, str):\n",
    "                g2 = strToGate(g2)\n",
    "\n",
    "            gate_layers = [g1, g2]\n",
    "            r1, r2 = self.r\n",
    "            reuse_params = self.reuse_params\n",
    "\n",
    "        super().__init__(ob_map, n_layers, n_single_qubit_params, GeneralQCInterface, discard, [Rx, Rz])\n",
    "\n",
    "    def params_shape(self, n_qubits: int) -> Tuple[int, ...]:\n",
    "        if self.reuse_params:\n",
    "            k = 1\n",
    "        else:\n",
    "            k = 2\n",
    "        \n",
    "        return (self.n_layers, k*self.gate_config[\"var_layers\"]*n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76391143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSA(Circuit):\n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import H, Rx, Rz, CX, Ry\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            if len(params) == 0:\n",
    "                circuit = Id(1)\n",
    "            else:\n",
    "                circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "        elif len(np.shape(params)) != 2\\\n",
    "                or np.shape(params)[1] != n_qubits - 1:\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits - 1))\n",
    "        else:\n",
    "            depth = np.shape(params)[0]\n",
    "            circuit = Id(n_qubits)\n",
    "\n",
    "            for thetas in params:\n",
    "                hadamards = Id().tensor(*(n_qubits * [H]))\n",
    "                rotations = Id(n_qubits).then(*(\n",
    "                    (Id(i) @ CX @ Id(n_qubits - 2 - i)) >> (Id(i + 1) @ Rz(thetas[i]) @ Id(n_qubits - 2 - i) >> (Id(i + 1) @ H @ Id(n_qubits - 2 - i)))\n",
    "                    for i in range(n_qubits - 1)))\n",
    "                circuit >>= hadamards >> rotations\n",
    "\n",
    "        super().__init__(circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class SimpleSAAnsatz(CircuitAnsatz):\n",
    "    def __init__(self, ob_map: Mapping[Ty, int], n_layers: int, n_single_qubit_params: int = 0, discard: bool = False) -> None:\n",
    "        super().__init__(ob_map, n_layers, n_single_qubit_params, SimpleSA, discard, [Rx, Rz], H)\n",
    "\n",
    "    def params_shape(self, n_qubits: int) -> Tuple[int, ...]:\n",
    "        return (self.n_layers, n_qubits - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, Rewriter, remove_cups\n",
    "from discopy import grammar\n",
    "from discopy.quantum.gates import X, Z\n",
    "from discopy import rigid\n",
    "\n",
    "def sentences_to_circuits(sentences, ansatz, convert_bigraph=True, not_representation=\"X\", all_sentences=None, return_valids_mask=True):\n",
    "    ### SENTENCES TO DIAGRAMS ###\n",
    "\n",
    "    if all_sentences is None:\n",
    "        all_sentences = sentences\n",
    "    \n",
    "    # syntax tree parsing\n",
    "    parser = BobcatParser()\n",
    "    raw_diagrams = parser.sentences2diagrams([text.replace(\" not \", \" \") for text in sentences])\n",
    "\n",
    "    # filter valid diagrams type S\n",
    "    n_sent = len(sentences)\n",
    "\n",
    "    valids_mask = np.array([d.cod.name == Ty('s').name for d in raw_diagrams])\n",
    "    data = [sentences[i] for i in range(n_sent) if valids_mask[i]]\n",
    "    use_diagrams = [raw_diagrams[i] for i in range(n_sent) if valids_mask[i]]\n",
    "\n",
    "    # grammatical rewrite rules\n",
    "    rewriter = Rewriter()\n",
    "    rewritten_diagrams = [rewriter(diagram) for diagram in use_diagrams]\n",
    "\n",
    "    # bigraph method\n",
    "    normalised_diagrams = [convertToTrailingCups(diagram.normal_form()) for diagram in rewritten_diagrams]\n",
    "\n",
    "    removed_diagrams = [remove_cups(diagram) for diagram in normalised_diagrams]\n",
    "\n",
    "    # stemming and lemmatization\n",
    "    stemmed_diagrams = [Rewriter([StemRewriteRule(all_sentences)])(diagram) for diagram in removed_diagrams]\n",
    "\n",
    "    # final diagrams\n",
    "    diagrams = [diagram for diagram in stemmed_diagrams]\n",
    "\n",
    "    ### DIAGRAMS to CIRCUITS ###\n",
    "\n",
    "    # string diagrams to raw quantum circuits\n",
    "    circuits = [ansatz(diagram) for diagram in diagrams]\n",
    "\n",
    "    # apply NOT box to circuits\n",
    "    for i, circuit in enumerate(circuits):\n",
    "        if data[i].find(\" not \") != -1:\n",
    "            if (not_representation == \"ZX\"):\n",
    "                circuits[i] = circuit >> Z >> X\n",
    "            else:\n",
    "                circuits[i] = circuit >> X\n",
    "    \n",
    "    if return_valids_mask:\n",
    "        return data, diagrams, circuits, valids_mask\n",
    "    else:\n",
    "        return data, diagrams, circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e0399",
   "metadata": {},
   "source": [
    "# Compile Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c474ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "working_dir = \"../data/experiment_results/journal/generalQC/\"\n",
    "experiment_book = []\n",
    "\n",
    "for experiment_name in os.listdir(working_dir):\n",
    "    experiment_dir = working_dir+experiment_name+\"/\"\n",
    "    if os.path.isdir(experiment_dir):\n",
    "        if \"test_800_accs.csv\" in os.listdir(experiment_dir) and \"faulty\" not in experiment_name:\n",
    "            experiment_dict = {\"name\": experiment_name}\n",
    "\n",
    "            with open(experiment_dir+\"params.txt\", \"r\") as f:\n",
    "                content = f.read().replace(\"\\'\", \"\\\"\")\n",
    "                params_dict = json.loads(content)\n",
    "                f.close()\n",
    "            \n",
    "            experiment_dict[\"params\"] = params_dict\n",
    "\n",
    "            info = experiment_name.split(\"_\")\n",
    "\n",
    "            experiment_dict[\"data_version\"] = info[0]\n",
    "\n",
    "            if info[1] == \"SimpleSA\":\n",
    "                experiment_dict[\"ansatz\"] = \"SimpleSAAnsatz\"\n",
    "            elif info[2] == \"IQP\":\n",
    "                experiment_dict[\"ansatz\"] = \"IQPAnsatz\"\n",
    "            else:\n",
    "                experiment_dict[\"ansatz\"] = \"GeneralQCAnsatz\"\n",
    "\n",
    "                experiment_dict[\"gate_layers\"] = [info[1], info[2][1:]]\n",
    "\n",
    "                experiment_dict[\"var_layers\"] = (info[1]+info[2]).count(\"R\")\n",
    "            \n",
    "            experiment_dict[\"n_layers\"] = 1\n",
    "\n",
    "            for i in info[1:]:\n",
    "                if \"iter\" in i:\n",
    "                    experiment_dict[\"iter\"] = int(i[:-4])\n",
    "                    break\n",
    "            \n",
    "            if \"no\" in info:\n",
    "                experiment_dict[\"parameterize_nouns\"] = False\n",
    "            elif \"with\" in info:\n",
    "                experiment_dict[\"parameterize_nouns\"] = True\n",
    "        \n",
    "            experiment_book.append(experiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "take = [\"v5_IQP_800iter\"]\n",
    "\n",
    "experiment_book_2 = [e for e in experiment_book if e[\"name\"] in take]\n",
    "\n",
    "experiment_book = [e for e in experiment_book_2]\n",
    "\n",
    "experiment_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25feee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import AerBackend\n",
    "\n",
    "backend = AerBackend()\n",
    "\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'n_shots': 8192  # maximum recommended shots, reduces sampling error\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy.quantum import Circuit, Id, Measure\n",
    "\n",
    "def randint(rng, low=-1 << 63, high=1 << 63-1):\n",
    "    return rng.integers(low, high)\n",
    "\n",
    "def normalise(predictions):\n",
    "    # apply smoothing to predictions\n",
    "    predictions = np.abs(predictions) + 1e-9\n",
    "    return predictions / predictions.sum()\n",
    "\n",
    "def make_pred_fn(circuits, parameters, rng):\n",
    "    measured_circuits = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuits]\n",
    "    circuit_fns = [c.lambdify(*parameters) for c in measured_circuits]\n",
    "\n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c_fn(*params) for c_fn in circuit_fns),\n",
    "                               **backend_config, seed=randint(rng))\n",
    "        return np.array([normalise(output.array) for output in outputs])\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import AtomicType, IQPAnsatz, Sim15Ansatz\n",
    "from sympy import default_sort_key\n",
    "\n",
    "\n",
    "def decapitate_circuit(circuit):\n",
    "    from discopy import Bra, Measure\n",
    "\n",
    "    cutoff = None\n",
    "\n",
    "    for i, box in enumerate(circuit.boxes):\n",
    "        if box in [Bra, Measure, Bra(0), Bra(0, 0)]:\n",
    "            cutoff = i\n",
    "            break\n",
    "    \n",
    "    return circuit[:i]\n",
    "\n",
    "def build_circuit_library(experiment_dict, data_src, targets_src):\n",
    "    name = experiment_dict[\"name\"]\n",
    "    params = experiment_dict[\"params\"]\n",
    "    ansatz_name = experiment_dict[\"ansatz\"]\n",
    "    n_layers = experiment_dict[\"n_layers\"]\n",
    "    spsa_n_iter = experiment_dict[\"iter\"]\n",
    "    parameterize_nouns = experiment_dict[\"parameterize_nouns\"]\n",
    "    \n",
    "    parameters = list(params.keys())\n",
    "    param_vals = [params[key] for key in parameters]\n",
    "\n",
    "    # build ansatz\n",
    "    N = AtomicType.NOUN\n",
    "    S = AtomicType.SENTENCE\n",
    "\n",
    "    if ansatz_name == \"IQPAnsatz\":\n",
    "        ansatz = IQPAnsatz({N: 1, S: 1}, n_layers=n_layers)\n",
    "    elif ansatz_name == \"SimpleSAAnsatz\":\n",
    "        ansatz = SimpleSAAnsatz({N: 1, S: 1}, n_layers=n_layers, n_single_qubit_params=3*int(parameterize_nouns))\n",
    "    elif ansatz_name == \"GeneralQCAnsatz\":\n",
    "        gate_layers = experiment_dict[\"gate_layers\"]\n",
    "        var_layers = experiment_dict[\"var_layers\"]\n",
    "        \n",
    "        ansatz = GeneralQCAnsatz({N: 1, S: 1}, n_layers=1, n_single_qubit_params=3*int(parameterize_nouns), gate_config={\"gate_layers\": gate_layers, \"var_layers\": var_layers}, r=(1, -1))\n",
    "    \n",
    "    data, diagrams, circuits, valids_mask = sentences_to_circuits(data_src, ansatz)\n",
    "    targets = [target for i, target in enumerate(targets_src) if valids_mask[i]]\n",
    "\n",
    "    circuit_heads = []\n",
    "\n",
    "    # instantiate complete circuits\n",
    "\n",
    "    SEED = 0\n",
    "    rng = np.random.default_rng(SEED)\n",
    "\n",
    "    use_parameters = sorted({s for circ in circuits for s in circ.free_symbols},key=default_sort_key)\n",
    "    use_param_strs = [str(param_sym) for param_sym in use_parameters]\n",
    "    use_param_vals = [val for i, val in enumerate(param_vals) if parameters[i] in use_param_strs]\n",
    "\n",
    "    measured_circuits = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuits]\n",
    "    circuit_fns = [c.lambdify(*use_parameters) for c in measured_circuits]\n",
    "    instantiated_circuits = [c_fn(*use_param_vals) for c_fn in circuit_fns]\n",
    "\n",
    "    outputs = Circuit.eval(*instantiated_circuits, **backend_config, seed=randint(rng))\n",
    "    res = np.array([normalise(output.array) for output in outputs])\n",
    "\n",
    "    circuit_heads = [decapitate_circuit(c) for c in circuits]\n",
    "\n",
    "    # measured_circuit_heads = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuit_heads]\n",
    "    circuit_head_fns = [c.lambdify(*use_parameters) for c in circuit_heads]\n",
    "    instantiated_circuit_heads = [c_fn(*use_param_vals) for c_fn in circuit_head_fns]\n",
    "\n",
    "    return data, targets, parameters, param_vals, diagrams, ansatz, circuits, instantiated_circuits, circuit_heads, instantiated_circuit_heads, outputs, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computational_bases(n_qubits):\n",
    "    return np.array([[int(j==i) for j in range(2**n_qubits)] for i in range(2**n_qubits)], dtype='cfloat')\n",
    "\n",
    "def tensor_prod(v2, v1):\n",
    "    return np.tensordot(v1, v2, axes=0).flatten()\n",
    "\n",
    "def bloch_bases(n_qubits, n_alpha, n_beta):\n",
    "    z_1 = computational_bases(1)\n",
    "    b_plus = lambda alpha, beta: np.cos(alpha/2)*z_1[0] + np.sin(alpha/2)*np.exp((0+1j)*beta)*z_1[1]\n",
    "    b_minus = lambda alpha, beta: np.sin(alpha/2)*z_1[0] - np.cos(alpha/2)*np.exp((0+1j)*beta)*z_1[1]\n",
    "\n",
    "    alpha_dom = np.linspace(0, np.pi, n_alpha)\n",
    "    beta_dom = np.linspace(0, 2*np.pi, n_beta)\n",
    "\n",
    "    def b_bases_paramx(thetas):\n",
    "        b_bases = computational_bases(0)\n",
    "\n",
    "        for i in range(n_qubits):\n",
    "            b_pluses = [tensor_prod(b_plus(thetas[2*i], thetas[2*i+1]), b_basis) for b_basis in b_bases]\n",
    "            b_minuses = [tensor_prod(b_minus(thetas[2*i], thetas[2*i+1]), b_basis) for b_basis in b_bases]\n",
    "\n",
    "            b_bases = np.vstack([b_pluses, b_minuses])\n",
    "        \n",
    "        return b_bases\n",
    "    \n",
    "    bloch_space = [None for _ in range((n_alpha*n_beta)**(n_qubits))]\n",
    "\n",
    "    def recursive_search(level, curr_idx=[], curr_thetas=[]):\n",
    "        for i, alpha0 in enumerate(alpha_dom):\n",
    "            for j, beta0 in enumerate(beta_dom):\n",
    "                if level == 1:\n",
    "                    index = 0\n",
    "                    for a_i, b_j in curr_idx+[[i, j]]:\n",
    "                        index = index*n_alpha*n_beta+a_i*n_alpha+b_j\n",
    "                    \n",
    "                    bloch_space[index] = b_bases_paramx(curr_thetas+[alpha0, beta0])\n",
    "                else:\n",
    "                    recursive_search(level-1, curr_idx+[[i, j]], curr_thetas+[alpha0, beta0])\n",
    "\n",
    "    recursive_search(n_qubits)\n",
    "\n",
    "    return bloch_space\n",
    "\n",
    "def trace(mat):\n",
    "    return np.cfloat(sum([mat[i][i] for i in range(len(mat))]))\n",
    "\n",
    "def abstrace(mat):\n",
    "    return float(sum([np.absolute(mat[i][i]) for i in range(len(mat))]))\n",
    "\n",
    "def KD(a, b, rho):\n",
    "    Pi_a = np.outer(a, np.conjugate(a))\n",
    "    Pi_b = np.outer(b, np.conjugate(b))\n",
    "    return trace(np.matmul(Pi_b, np.matmul(Pi_a, rho)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5723c753",
   "metadata": {},
   "source": [
    "# Build Haar Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b65ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "def build_clifford_set(n_qubits, cliffords=[]):\n",
    "    single_qubit_cliffords = [\n",
    "        '',\n",
    "        'H', 'S',\n",
    "        'HS', 'SH', 'SS',\n",
    "        'HSH', 'HSS', 'SHS', 'SSH', 'SSS',\n",
    "        'HSHS', 'HSSH', 'HSSS', 'SHSS', 'SSHS',\n",
    "        'HSHSS', 'HSSHS', 'SHSSH', 'SHSSS', 'SSHSS',\n",
    "        'HSHSSH', 'HSHSSS', 'HSSHSS'\n",
    "    ]\n",
    "\n",
    "    if n_qubits == 0:\n",
    "        return cliffords\n",
    "    else:\n",
    "        if len(cliffords) == 0:\n",
    "            return build_clifford_set(n_qubits-1, [[sc] for sc in single_qubit_cliffords])\n",
    "        else:\n",
    "            temp_cliffords = [[c+[sc] for sc in single_qubit_cliffords] for c in cliffords]\n",
    "            new_cliffords = [item for sublist in temp_cliffords for item in sublist]\n",
    "\n",
    "            return build_clifford_set(n_qubits-1, new_cliffords)\n",
    "\n",
    "def build_clifford_states(n_qubits):\n",
    "    backend = Aer.get_backend('unitary_simulator')\n",
    "\n",
    "    multi_qubit_cliffords = build_clifford_set(n_qubits)\n",
    "    mqc_svs = [clifford_str_to_sv(c, backend) for c in multi_qubit_cliffords]\n",
    "\n",
    "    return mqc_svs\n",
    "\n",
    "def clifford_str_to_sv(clifford_str, backend):\n",
    "    n_qubits = len(clifford_str)\n",
    "\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "\n",
    "    for i in range(n_qubits):\n",
    "        for j, gate in enumerate(clifford_str[i]):\n",
    "            if gate == \"H\":\n",
    "                qc.h(n_qubits-i-1)\n",
    "            if gate == \"S\":\n",
    "                qc.s(n_qubits-i-1)\n",
    "    \n",
    "    qc.save_unitary()\n",
    "\n",
    "    job = transpile(qc, backend)\n",
    "    job_result = backend.run(job).result()\n",
    "\n",
    "    return job_result.get_unitary(qc).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_qubit_cliffords = {}\n",
    "\n",
    "for n_qubits in [2, 3, 4]:\n",
    "    multi_qubit_cliffords[n_qubits] = build_clifford_states(n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90479e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/coherence_utils/mqc_vals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(multi_qubit_cliffords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d363d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_bases = {2: computational_bases(2), 3: computational_bases(3), 4: computational_bases(4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9175158",
   "metadata": {},
   "source": [
    "# Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a00c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "coherence_dict = {}\n",
    "\n",
    "for k, experiment_dict in enumerate(experiment_book):\n",
    "    if experiment_dict[\"name\"] in coherence_dict:\n",
    "        experiment_book[k][\"NCLs\"] = np.array(coherence_dict[experiment_dict[\"name\"]][\"ncls\"])\n",
    "        experiment_book[k][\"coherence\"] = coherence_dict[experiment_dict[\"name\"]][\"avg\"]\n",
    "        continue\n",
    "    \n",
    "    data, targets, parameters, param_vals, diagrams, ansatz, circuits, instantiated_circuits, circuit_heads, instantiated_circuit_heads, outputs, res = build_circuit_library(experiment_dict, test_data_src, test_targets_src)\n",
    "    sv_data = [c.to_tk().get_statevector() for c in instantiated_circuit_heads]\n",
    "\n",
    "    NCLs = [None for _ in sv_data]\n",
    "\n",
    "    sv_lengths = [len(sv) for sv in sv_data]\n",
    "    sv_sorted = [x for _, x in sorted(zip(sv_lengths, sv_data), key=lambda pair: pair[0])]\n",
    "    sv_lengths_sorted = [x for x, _ in sorted(zip(sv_lengths, sv_data), key=lambda pair: pair[0])]\n",
    "\n",
    "    dim = sv_lengths_sorted[0]\n",
    "    i = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while i < len(sv_data):\n",
    "        i0 = i\n",
    "        while i < len(sv_data) and sv_lengths_sorted[i] == dim:\n",
    "            i += 1\n",
    "        \n",
    "        sv_use = sv_sorted[i0:i]\n",
    "        print(experiment_dict[\"name\"], dim, i)\n",
    "\n",
    "        n_qubits = int(math.log2(dim))\n",
    "\n",
    "        if n_qubits not in multi_qubit_cliffords:\n",
    "            multi_qubit_cliffords[n_qubits] = build_clifford_states(n_qubits)\n",
    "        if n_qubits not in z_bases:\n",
    "            z_bases[n_qubits] = computational_bases(n_qubits)\n",
    "        \n",
    "        rhos = [np.outer(sv, sv.conjugate()) for sv in sv_use]\n",
    "\n",
    "        y_max = np.array([-1 for _ in sv_use], dtype='float')\n",
    "\n",
    "        for haar_basis in tqdm(multi_qubit_cliffords[n_qubits]):\n",
    "            kd_sums = np.array([-1 for _ in sv_use], dtype='float')\n",
    "            \n",
    "            for hs in haar_basis:\n",
    "                Pi_b = np.outer(hs, hs.conjugate())\n",
    "                kd_sum = np.array([abstrace(np.matmul(Pi_b, rho)) for rho in rhos], dtype='float')\n",
    "                kd_sums += kd_sum\n",
    "                \n",
    "            y_max = y_max*(y_max > kd_sums) + kd_sums*(kd_sums >= y_max)\n",
    "\n",
    "        for j in range(i0, i):\n",
    "            NCLs[j] = y_max[j-i0]\n",
    "        if i < len(sv_data):\n",
    "            dim = sv_lengths_sorted[i]\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    experiment_book[k][\"NCLs\"] = NCLs\n",
    "    experiment_book[k][\"coherence\"] = sum(NCLs)/len(NCLs)\n",
    "    coherence_dict[experiment_dict[\"name\"]] = {\"name\": NCLs, \"avg\": sum(NCLs)/len(NCLs)}\n",
    "\n",
    "    print(experiment_dict[\"name\"], NCLs, sum(NCLs)/len(NCLs))\n",
    "    print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in experiment_book:\n",
    "    print(e[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7145a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
