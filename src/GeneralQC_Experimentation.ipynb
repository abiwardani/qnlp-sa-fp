{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Parameters\n",
    "\n",
    "# Experiment conditions\n",
    "use_all_rewriter_rules = True\n",
    "convert_bigraph = True\n",
    "not_representation = \"X\"\n",
    "not_placement = \"end\"\n",
    "gate_layers = [\"Rx\", \"Rz\"]\n",
    "var_layers = 2\n",
    "parameterize_nouns = True\n",
    "gate_layers = [\"Rx\", \"Rz\"]\n",
    "var_layers = 2\n",
    "parameterize_nouns = True\n",
    "# independent_sublayer = False\n",
    "\n",
    "# load params\n",
    "train_params = False\n",
    "load_params = True\n",
    "param_vals = [1.3505649493072467, -0.14966328435185, 0.04675537879798401, -0.0015354611799713639, 0.8467703608674717, 1.5964349654020935, 0.9415552599593355, 0.7916802060431765, 0.09940955754857185, 1.3473293118007097, 0.5579013343383226, -0.2679104960784575, 0.3776135427626039, 0.62703035023651, 0.4285010663953328, 0.019792381213966686, 0.940842946083086, 0.33781388773672416, 0.8487456927074848, 0.7556821018373534, -0.5608258781490134, 0.36476364832952235, 1.0737220311034188, -0.1124067666176007, 0.08191140893146531, -0.3822700356542936, 1.7675583352903093, 1.157455792341757, 0.17848596573971048, 0.4316137952186831, 0.8206557377751482, 0.6847553524509737, 0.05400777268978768, 1.2013720181631076, 0.28904507119386325, 0.06465854055487004, -0.09416797215962379, 1.051771804895434, 0.7506276718251563, 0.3884711100982121, 0.8482724716958543, 0.8149804380340482, 0.7896084168659374, 0.3496117177218967, 0.6011503910365614, 1.5729679680184632, 0.9792834796934351, 0.41266904602145826, -0.26523798248283115, 0.29819378568686317, 0.9586926117734706, 0.40703254844620307, 1.0296364797336521, 0.17863789971485083, -0.008456234920267822, 0.48771312748188433, 0.05076209488566123, 1.3298132342611912, -0.5878522477674955, 0.4067109276060562, 0.4423094947759354, 0.32301125698163086, 0.593848336018743, 0.6526038095556363, -0.4966519491527389, 0.6415696668260122, 0.7906445725342086, 1.5599899677343447, 0.558077628311284, -0.11041397551907499, 0.5957225862423388, 1.1732862757098548, -0.2265062280939964, 1.5044824049304453, -0.0533738041658748, 0.33420598890680564, 1.196245190159652, 0.9697961143224758, 0.6533425442624752, 0.08669834541405962, 0.48807237501014855, 1.0485106762146703, 1.0621443507152275, 0.9252129972582814, 0.9548661806967234, 0.9692520279388916, 1.170143153963476, 1.4122822854880106, 0.46545972319331497, 0.630801420187417, 0.40534540594920576]\n",
    "# params_saved = {'I__n_0': 1.3926202901320248, 'I__n_1': 0.008448820382520305, 'I__n_2': -0.6385783774702594, 'aw__n.r@s_0': 0.004878974097219957, 'aw__n@n.l_0': -1.710437394121971, 'bad__n.r@s_0': -2.0120646244526674, 'bad__n@n.l_0': -0.33328110433838587, 'bland__n.r@s_0': -1.8011492489090937, 'bland__n@n.l_0': -0.23301002690494765, 'cook__n.r@s@n.l_0': 2.666641605278804, 'cook__n.r@s@n.l_1': 0.35782850997078663, 'delici__n.r@s_0': -0.6784353476839611, 'delici__n@n.l_0': 2.5048532581915994, 'dislik__n.r@s@n.l_0': 1.264688638132907, 'dislik__n.r@s@n.l_1': 2.9058201511277773, 'fast__n.r@s_0': 1.5228059027468268, 'fast__n@n.l_0': 1.4318617692717328, 'food__n_0': 0.9510109180885518, 'food__n_1': 1.983545943335132, 'food__n_2': 0.31422754989262236, 'good__n.r@s_0': -0.37898061288101936, 'good__n@n.l_0': 0.3417258364922475, 'great__n.r@s_0': 0.32023762451562343, 'great__n@n.l_0': 1.9344786256084243, 'had__n.r@s@n.l_0': 0.9175005505289897, 'had__n.r@s@n.l_1': -1.126491771734188, 'hate__n.r@s@n.l_0': 1.0178843262642405, 'hate__n.r@s@n.l_1': -0.8544213946932742, 'impecc__n.r@s_0': 0.8774940821788493, 'impecc__n@n.l_0': 0.28533233081922516, 'like__n.r@s@n.l_0': 0.5238711836690633, 'like__n.r@s@n.l_1': -0.0248482491004431, 'love__n.r@s@n.l_0': -1.0716522290529822, 'love__n.r@s@n.l_1': 0.4674574117431039, 'meal__n_0': -0.2913227630628624, 'meal__n_1': -0.7824158049259571, 'meal__n_2': 2.364685233940882, 'nice__n.r@s_0': -0.31906215984000647, 'nice__n@n.l_0': -2.087345064482271, 'restaur__n_0': 1.9567881690203595, 'restaur__n_1': 0.35319298096689367, 'restaur__n_2': -0.5953604557383299, 'rude__n.r@s_0': 2.1631540155864895, 'rude__n@n.l_0': -0.9753409914505806, 'servic__n_0': -2.7047864895209357, 'servic__n_1': 1.2351321590961786, 'servic__n_2': -1.5851261977616085, 'show__n.r@s@n.l_0': -0.6393012792612347, 'show__n.r@s@n.l_1': 1.7857303585103954, 'slow__n.r@s_0': 0.5156333465906835, 'slow__n@n.l_0': 1.0425765284092643, 'staff__n_0': 0.08543447326700565, 'staff__n_1': -2.068154595353262, 'staff__n_2': 0.019379227469981927, 'tasti__n.r@s_0': 1.2246133069435021, 'tasti__n@n.l_0': 1.9668107229444722, 'terribl__n.r@s_0': -0.3440262636975905, 'terribl__n@n.l_0': 2.1861199395142688, 'unappet__n.r@s_0': 1.440589048292482, 'unappet__n@n.l_0': -0.31598863954665035, 'wa__s@s.l_0': -1.0244128683696618}\n",
    "spsa_a = 0.2\n",
    "spsa_c = 0.06\n",
    "spsa_n_iter = 800\n",
    "k0 = 800\n",
    "\n",
    "# SVM type\n",
    "kernel = 'rbf'\n",
    "default_svm = True\n",
    "optimize_svm = False\n",
    "\n",
    "# Experiment metadata\n",
    "experiment_name = \"v5_IQP_800iter\"\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "if (experiment_name == \"\"):\n",
    "    experiment_name = \"misc\"\n",
    "\n",
    "path = '../data/experiment_results/journal/generalQC/'+experiment_name\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except:\n",
    "    print(\"experiment folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(path+'/params_raw.txt') as f:\n",
    "        data = f.read().replace('\\'', '\\\"')\n",
    "        params_saved = json.loads(data)\n",
    "except:\n",
    "    params_saved = None\n",
    "    train_params = True\n",
    "    load_params = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_data(filename):\n",
    "    labels, sentences = [], []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            labels.append([1, 0] if line[0] == '1' else [0, 1])\n",
    "            sentences.append(line[1:].strip())\n",
    "    return np.array(labels), sentences\n",
    "\n",
    "test_targets_src, test_data_src = read_data('../data/datasets/restaurant_v5_test.txt')\n",
    "dev_targets_src, dev_data_src = read_data('../data/datasets/restaurant_v5_dev.txt')\n",
    "train_targets_src, train_data_src = read_data('../data/datasets/restaurant_v5_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for converting to bigraph\n",
    "\n",
    "from discopy.rigid import Id as RigidId\n",
    "\n",
    "def checkTrailingCups(diagram):\n",
    "    scanWords = True\n",
    "    \n",
    "    for box in diagram.boxes:\n",
    "        if not box.dom and not scanWords:\n",
    "            return False\n",
    "        else:\n",
    "            scanWords = scanWords and not box.dom\n",
    "    \n",
    "    return True\n",
    "\n",
    "def convertToTrailingCups(diagram):\n",
    "    if (checkTrailingCups(diagram)):\n",
    "        return diagram\n",
    "\n",
    "    words = []\n",
    "    cups = []\n",
    "    \n",
    "    for box in diagram.boxes:\n",
    "        if not box.dom:\n",
    "            words = words + [box]\n",
    "        else:\n",
    "            cups = [box] + cups\n",
    "    \n",
    "    new_diag = words[0]\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if i != 0:\n",
    "            new_diag = new_diag >> RigidId(new_diag.cod) @ word\n",
    "    \n",
    "    for i, cup in enumerate(cups):\n",
    "        if i != len(cups)-1:\n",
    "            new_diag = new_diag >> RigidId(new_diag.cod[:-2]) @ cup\n",
    "        else:\n",
    "            new_diag = new_diag >> cup @ RigidId(new_diag.cod[2:])\n",
    "    \n",
    "    return new_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion for stemming and lemmatization of tokens\n",
    "\n",
    "def to_word_tokens(data):\n",
    "    return [word_tokenize(record) for record in data]\n",
    "\n",
    "def build_stem_dictionary(data):\n",
    "    port = PorterStemmer()\n",
    "    wnet = WordNetLemmatizer()\n",
    "    \n",
    "    mapping = {}\n",
    "    \n",
    "    data_as_tokens = to_word_tokens(data)\n",
    "    \n",
    "    for words in data_as_tokens:\n",
    "        for word in words:\n",
    "            if word not in mapping:\n",
    "                stemmed_word = port.stem(word)\n",
    "                lemmatized_word = wnet.lemmatize(stemmed_word)\n",
    "                \n",
    "                mapping[word] = lemmatized_word\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for stemming and lemmatization of diagram boxes\n",
    "\n",
    "from lambeq.rewrite import RewriteRule\n",
    "\n",
    "class StemRewriteRule(RewriteRule):\n",
    "    def __init__(self, data):\n",
    "        self.mapping = build_stem_dictionary(data)\n",
    "    \n",
    "    def matches(self, box):\n",
    "        return box.name in self.mapping\n",
    "\n",
    "    def rewrite(self, box):\n",
    "        new_name = self.mapping[box.name]\n",
    "        return type(box)(name=new_name, dom=box.dom, cod=box.cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq.ansatz import CircuitAnsatz\n",
    "from abc import abstractmethod\n",
    "# from collections.abc import Mapping\n",
    "from itertools import cycle\n",
    "from typing import Callable, Optional, Tuple, Mapping\n",
    "from discopy.quantum.circuit import (Circuit, Functor, Id, qubit)\n",
    "from discopy.quantum.gates import Bra, Ket, Controlled, Rotation\n",
    "from discopy.quantum.gates import H, X, Y, Z, Rx, Ry, Rz\n",
    "from discopy.rigid import Box, Diagram, Ty\n",
    "from discopy.tensor import Dim, Tensor\n",
    "import numpy as np\n",
    "from sympy import Symbol, symbols\n",
    "\n",
    "class GeneralQCLayer(Circuit):\n",
    "    \n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import Rx, Rz\n",
    "\n",
    "        if len(self.gate_layers) != 2:\n",
    "            raise ValueError(\"Expected gate_layers as tuple of strings\")\n",
    "        \n",
    "        g1, g2 = self.gate_layers\n",
    "\n",
    "        if (g1 == None) or (g2 == None):\n",
    "            raise ValueError(\"gate_layers must be in discopy.quantum.gates\")\n",
    "        # if not (abs(self.r1) == 1 and abs(self.r2) == 1) and ((abs(self.r1) == 1 or abs(self.r2) == 1) and (self.r2 % self.r1 == 0 or self.r1 % self.r2 == 0)) or (n_qubits % self.r1 == 0 and self.r1 != 1) or (n_qubits % self.r2 == 0 and self.r2 != 1):\n",
    "        #     raise ValueError(\"n_qubits, r1, and r2 must be co-prime\")\n",
    "\n",
    "        params_shape = np.shape(params)\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            if len(params) == 0:\n",
    "                circuit = Id(1)\n",
    "            else:\n",
    "                circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "        elif (len(params_shape) != 2):\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits))\n",
    "        else:\n",
    "            g1_thetas = 0\n",
    "            g2_thetas = 0\n",
    "\n",
    "            if g1.free_symbols != {}:\n",
    "                # g1 is fixed\n",
    "                g1_thetas = n_qubits\n",
    "            if g2.free_symbols != {}:\n",
    "                g2_thetas = n_qubits\n",
    "\n",
    "            if self.reuse_params:\n",
    "                self.k = 1\n",
    "            else:\n",
    "                self.k = 2\n",
    "            \n",
    "            n_thetas = self.k*(g1_thetas + g2_thetas)\n",
    "\n",
    "            if (params_shape[1] != n_thetas):\n",
    "                raise ValueError(\n",
    "                    \"Expected component params with length {}\".format(n_thetas))\n",
    "\n",
    "            # ANSATZ ALGORITHM\n",
    "            circuit = Id(n_qubits)\n",
    "            \n",
    "            # for {theta} in labelled params\n",
    "            for thetas in params:\n",
    "                \n",
    "                # sublayer 1 non-entangling block\n",
    "                if g1_thetas == 0:\n",
    "                    # if g1 is fixed\n",
    "                    sublayer1 = Id().tensor(*([g1 for _ in range(n_qubits)]))\n",
    "                else:\n",
    "                    # if g1 is trainable\n",
    "                    sublayer1 = Id().tensor(*([g1(theta) for theta in thetas[:g1_thetas]]))\n",
    "                \n",
    "                # sublayer 1 entangled block\n",
    "                ctrl = 0\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    # shift target := control - r1\n",
    "                    tgt = (ctrl - self.r1) % n_qubits\n",
    "                    \n",
    "                    if g2_thetas == 0:\n",
    "                        sublayer1 = sublayer1._apply_controlled(g2, ctrl, tgt)\n",
    "                        # sublayer1 = sublayer1.CX(ctrl, tgt)\n",
    "                    else:\n",
    "                        sublayer1 = sublayer1._apply_controlled(g2(thetas[g1_thetas + i]), ctrl, tgt)\n",
    "                        # sublayer1 = sublayer1.CRx(thetas[g1_thetas + i], ctrl, tgt)\n",
    "                    \n",
    "                    ctrl = tgt\n",
    "                \n",
    "                # sublayer 2 non-entangling block\n",
    "                if g1_thetas == 0:\n",
    "                    sublayer2 = Id().tensor(*([g1 for _ in range(n_qubits)]))\n",
    "                else:\n",
    "                    if self.reuse_params:\n",
    "                        sublayer2 = Id().tensor(*([g1(theta) for theta in thetas[:g1_thetas]]))\n",
    "                    else:\n",
    "                        sublayer2 = Id().tensor(*([g1(theta) for theta in thetas[g1_thetas+g2_thetas:2*g1_thetas+g2_thetas]]))\n",
    "                \n",
    "                # sublayer 2 entangled block\n",
    "                ctrl = 0\n",
    "\n",
    "                for i in range(n_qubits):\n",
    "                    # shift target := control - r2\n",
    "                    tgt = (ctrl - self.r2) % n_qubits\n",
    "\n",
    "                    if g2_thetas == 0:\n",
    "                        sublayer2 = sublayer2._apply_controlled(g2, ctrl, tgt)\n",
    "                        # sublayer2 = sublayer2.CX(ctrl, tgt)\n",
    "                    else:\n",
    "                        if self.reuse_params:\n",
    "                            sublayer2 = sublayer2._apply_controlled(g2(thetas[g1_thetas + i]), ctrl, tgt)\n",
    "                        else:\n",
    "                            sublayer2 = sublayer2._apply_controlled(g2(thetas[2*g1_thetas+g2_thetas+i]), ctrl, tgt)\n",
    "                            # sublayer2 = sublayer2.CRx(thetas[2*g1_thetas+g2_thetas+i], ctrl, tgt)\n",
    "                    \n",
    "                    ctrl = tgt\n",
    "            \n",
    "                # compose circuit\n",
    "                circuit >>= sublayer1 >> sublayer2\n",
    "            \n",
    "        super().__init__(\n",
    "            circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class GeneralQCAnsatz(CircuitAnsatz):\n",
    "    def __init__(self, ob_map: Mapping[Ty, int], n_layers: int, n_single_qubit_params: int = 0, gate_config = {\"gate_layers\": [H, Rx], \"var_layers\": 1}, r = (1, 3), reuse_params=True, discard: bool = False) -> None:\n",
    "        self.gate_config = gate_config\n",
    "        self.reuse_params = reuse_params\n",
    "        self.r = r\n",
    "        \n",
    "        class GeneralQCInterface(GeneralQCLayer):\n",
    "            \"\"\" Interface for GeneralQCLayer \"\"\"\n",
    "\n",
    "            def strToGate(gateStr):\n",
    "                if gateStr == \"H\":\n",
    "                    return H\n",
    "                if gateStr == \"X\":\n",
    "                    return X\n",
    "                if gateStr == \"Y\":\n",
    "                    return Y\n",
    "                if gateStr == \"Z\":\n",
    "                    return Z\n",
    "                if gateStr == \"Rx\":\n",
    "                    return Rx\n",
    "                if gateStr == \"Ry\":\n",
    "                    return Ry\n",
    "                if gateStr == \"Rz\":\n",
    "                    return Rz\n",
    "                \n",
    "                return Id(1)\n",
    "            \n",
    "            assert(len(self.gate_config[\"gate_layers\"]) == 2)\n",
    "\n",
    "            g1, g2 = self.gate_config[\"gate_layers\"]\n",
    "\n",
    "            if isinstance(g1, str):\n",
    "                g1 = strToGate(g1)\n",
    "            if isinstance(g2, str):\n",
    "                g2 = strToGate(g2)\n",
    "\n",
    "            gate_layers = [g1, g2]\n",
    "            r1, r2 = self.r\n",
    "            reuse_params = self.reuse_params\n",
    "\n",
    "        super().__init__(ob_map, n_layers, n_single_qubit_params, GeneralQCInterface, discard, [Rx, Rz])\n",
    "\n",
    "    def params_shape(self, n_qubits: int) -> Tuple[int, ...]:\n",
    "        if self.reuse_params:\n",
    "            k = 1\n",
    "        else:\n",
    "            k = 2\n",
    "        \n",
    "        return (self.n_layers, k*self.gate_config[\"var_layers\"]*n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSA(Circuit):\n",
    "    def __init__(self, n_qubits, params):\n",
    "        from discopy.quantum.gates import H, Rx, Rz, CX, Ry\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            if len(params) == 0:\n",
    "                circuit = Id(1)\n",
    "            else:\n",
    "                circuit = Rx(params[0]) >> Rz(params[1]) >> Rx(params[2])\n",
    "        elif len(np.shape(params)) != 2\\\n",
    "                or np.shape(params)[1] != n_qubits - 1:\n",
    "            raise ValueError(\n",
    "                \"Expected params of shape (depth, {})\".format(n_qubits - 1))\n",
    "        else:\n",
    "            depth = np.shape(params)[0]\n",
    "            circuit = Id(n_qubits)\n",
    "\n",
    "            for thetas in params:\n",
    "                hadamards = Id().tensor(*(n_qubits * [H]))\n",
    "                rotations = Id(n_qubits).then(*(\n",
    "                    (Id(i) @ CX @ Id(n_qubits - 2 - i)) >> (Id(i + 1) @ Rz(thetas[i]) @ Id(n_qubits - 2 - i) >> (Id(i + 1) @ H @ Id(n_qubits - 2 - i)))\n",
    "                    for i in range(n_qubits - 1)))\n",
    "                circuit >>= hadamards >> rotations\n",
    "\n",
    "        super().__init__(circuit.dom, circuit.cod, circuit.boxes, circuit.offsets)\n",
    "\n",
    "class SimpleSAAnsatz(CircuitAnsatz):\n",
    "    def __init__(self, ob_map: Mapping[Ty, int], n_layers: int, n_single_qubit_params: int = 0, discard: bool = False) -> None:\n",
    "        super().__init__(ob_map, n_layers, n_single_qubit_params, SimpleSA, discard, [Rx, Rz], H)\n",
    "\n",
    "    def params_shape(self, n_qubits: int) -> Tuple[int, ...]:\n",
    "        return (self.n_layers, n_qubits - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, Rewriter, remove_cups\n",
    "from discopy import grammar\n",
    "from discopy.quantum.gates import X, Z\n",
    "from discopy import rigid\n",
    "\n",
    "def sentences_to_circuits(sentences, ansatz, convert_bigraph=True, not_representation=\"X\", all_sentences=None, return_valids_mask=True):\n",
    "    ### SENTENCES TO DIAGRAMS ###\n",
    "\n",
    "    if all_sentences is None:\n",
    "        all_sentences = sentences\n",
    "    \n",
    "    # syntax tree parsing\n",
    "    parser = BobcatParser()\n",
    "    raw_diagrams = parser.sentences2diagrams([text.replace(\" not \", \" \") for text in sentences])\n",
    "\n",
    "    # filter valid diagrams type S\n",
    "    n_sent = len(sentences)\n",
    "\n",
    "    valids_mask = np.array([d.cod.name == Ty('s').name for d in raw_diagrams])\n",
    "    data = [sentences[i] for i in range(n_sent) if valids_mask[i]]\n",
    "    use_diagrams = [raw_diagrams[i] for i in range(n_sent) if valids_mask[i]]\n",
    "\n",
    "    # grammatical rewrite rules\n",
    "    rewriter = Rewriter()\n",
    "    rewritten_diagrams = [rewriter(diagram) for diagram in use_diagrams]\n",
    "\n",
    "    # bigraph method\n",
    "    normalised_diagrams = [convertToTrailingCups(diagram.normal_form()) for diagram in rewritten_diagrams]\n",
    "\n",
    "    removed_diagrams = [remove_cups(diagram) for diagram in normalised_diagrams]\n",
    "\n",
    "    # stemming and lemmatization\n",
    "    stemmed_diagrams = [Rewriter([StemRewriteRule(all_sentences)])(diagram) for diagram in removed_diagrams]\n",
    "\n",
    "    # final diagrams\n",
    "    diagrams = [diagram for diagram in stemmed_diagrams]\n",
    "\n",
    "    ### DIAGRAMS to CIRCUITS ###\n",
    "\n",
    "    # string diagrams to raw quantum circuits\n",
    "    circuits = [ansatz(diagram) for diagram in diagrams]\n",
    "\n",
    "    # apply NOT box to circuits\n",
    "    for i, circuit in enumerate(circuits):\n",
    "        if data[i].find(\" not \") != -1:\n",
    "            if (not_representation == \"ZX\"):\n",
    "                circuits[i] = circuit >> Z >> X\n",
    "            else:\n",
    "                circuits[i] = circuit >> X\n",
    "    \n",
    "    if return_valids_mask:\n",
    "        return data, diagrams, circuits, valids_mask\n",
    "    else:\n",
    "        return data, diagrams, circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import AtomicType, IQPAnsatz\n",
    "from discopy.quantum.gates import H, X, Y, Z, Rx, Ry, Rz\n",
    "\n",
    "# Define atomic types\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "\n",
    "# Convert string diagram to quantum circuit\n",
    "ansatz = IQPAnsatz({N: 1, S: 1}, n_layers=1)\n",
    "# ansatz = GeneralQCAnsatz({N: 1, S: 1}, n_layers=1, n_single_qubit_params=3*int(parameterize_nouns), gate_config={\"gate_layers\": gate_layers, \"var_layers\": var_layers}, r=(1, -1))\n",
    "# ansatz = SimpleSAAnsatz({N: 1, S: 1}, n_layers=1, n_single_qubit_params=3*int(parameterize_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_diagrams, train_circuits, train_valids_mask = sentences_to_circuits(train_data_src, ansatz)\n",
    "dev_data, dev_diagrams, dev_circuits, dev_valids_mask = sentences_to_circuits(dev_data_src, ansatz)\n",
    "test_data, test_diagrams, test_circuits, test_valids_mask = sentences_to_circuits(test_data_src, ansatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = [train_targets_src[i] for i, mask in enumerate(train_valids_mask) if mask]\n",
    "dev_targets = [dev_targets_src[i] for i, mask in enumerate(dev_valids_mask) if mask]\n",
    "test_targets = [test_targets_src[i] for i, mask in enumerate(test_valids_mask) if mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import AerBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure backend\n",
    "backend = AerBackend()\n",
    "\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'n_shots': 8192  # maximum recommended shots, reduces sampling error\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy.quantum import Circuit, Id, Measure\n",
    "\n",
    "def randint(rng, low=-1 << 63, high=1 << 63-1):\n",
    "    return rng.integers(low, high)\n",
    "\n",
    "def normalise(predictions):\n",
    "    # apply smoothing to predictions\n",
    "    predictions = np.abs(predictions) + 1e-9\n",
    "    return predictions / predictions.sum()\n",
    "\n",
    "def make_pred_fn(circuits, parameters, rng):\n",
    "    measured_circuits = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuits]\n",
    "    circuit_fns = [c.lambdify(*parameters) for c in measured_circuits]\n",
    "\n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c_fn(*params) for c_fn in circuit_fns),\n",
    "                               **backend_config, seed=randint(rng))\n",
    "        return np.array([normalise(output.array) for output in outputs])\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noisyopt import OptimizeResult\n",
    "\n",
    "def myMinimizeSPSA(func, x0, args=(), bounds=None, niter=100, paired=True,\n",
    "                 a=1.0, c=1.0, k0=0,\n",
    "                 disp=False, callback=None):\n",
    "    \"\"\"\n",
    "    Minimization of an objective function by a simultaneous perturbation\n",
    "    stochastic approximation algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func: callable\n",
    "        objective function to be minimized\n",
    "    x0: array-like\n",
    "        starting point\n",
    "    args: tuple\n",
    "        extra arguments to be supplied to func\n",
    "    bounds: array-like\n",
    "        bounds on the variables\n",
    "    scaling: array-like\n",
    "        scaling by which to multiply step size and tolerances along different dimensions\n",
    "    niter: int\n",
    "        maximum number of iterations of the algorithm\n",
    "    paired: boolean\n",
    "        calculate gradient for same random seeds\n",
    "    a: float\n",
    "       algorithm scaling parameter for step size\n",
    "    c: float\n",
    "       algorithm scaling parameter for evaluation step size\n",
    "    disp: boolean\n",
    "        whether to output status updates during the optimization\n",
    "    callback: callable\n",
    "        called after each iteration, as callback(xk), where xk is the current parameter vector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scipy.optimize.OptimizeResult object\n",
    "    \"\"\"\n",
    "    A = 0.01 * niter\n",
    "    # A = 0.01 * niter\n",
    "    alpha = 0.602\n",
    "    gamma = 0.101\n",
    "\n",
    "    if bounds is None:\n",
    "        project = lambda x: x\n",
    "    else:\n",
    "        bounds = np.asarray(bounds)\n",
    "        project = lambda x: np.clip(x, bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "    if args is not None:\n",
    "        # freeze function arguments\n",
    "        def funcf(x, **kwargs):\n",
    "            return func(x, *args, **kwargs)\n",
    "\n",
    "    N = len(x0)\n",
    "    x = x0\n",
    "    for k in range(k0, niter):\n",
    "        ak = a/(k+1.0+A)**alpha\n",
    "        ck = c/(k+1.0)**gamma\n",
    "        delta = np.random.choice([-1, 1], size=N)\n",
    "        fkwargs = {\"k\": k+1}\n",
    "        if paired:\n",
    "            fkwargs['seed'] = np.random.randint(0, np.iinfo(np.uint32).max, dtype=np.int64)\n",
    "        if bounds is None:\n",
    "            grad = (funcf(x + ck*delta, **fkwargs) - funcf(x - ck*delta, **fkwargs)) / (2*ck*delta)\n",
    "        else:\n",
    "            # ensure evaluation points are feasible\n",
    "            xplus = project(x + ck*delta)\n",
    "            xminus = project(x - ck*delta)\n",
    "            grad = (funcf(xplus, **fkwargs) - funcf(xminus, **fkwargs)) / (xplus-xminus)\n",
    "        x = project(x - ak*grad)\n",
    "\n",
    "        # print 100 status updates if disp=True\n",
    "        if disp and (k % (niter//100)) == 0:\n",
    "            print(x)\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "    message = 'terminated after reaching max number of iterations'\n",
    "    return OptimizeResult(fun=funcf(x), x=x, nit=niter, nfev=2*niter, message=message, success=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noisyopt import minimizeSPSA\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import default_sort_key\n",
    "import gc\n",
    "\n",
    "class Result:\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "def make_cost_fn(pred_fn, labels, directory, name):\n",
    "    if name == \"test\":\n",
    "        with open(f'{directory}/{name}_costs.csv', 'w') as f:\n",
    "            pass\n",
    "    \n",
    "    if name == \"test\":\n",
    "        with open(f'{directory}/{name}_accs.csv', 'w') as f:\n",
    "            pass\n",
    "\n",
    "    if name == \"test\":\n",
    "        with open(f'{directory}/params_raw.txt', 'w') as f:\n",
    "            pass\n",
    "    \n",
    "    def cost_fn(params, **kwargs):\n",
    "        predictions = pred_fn(params)\n",
    "\n",
    "        cost = -np.sum(labels * np.log(predictions)) / len(labels)  # binary cross-entropy loss\n",
    "        \n",
    "        with open(f'{directory}/{name}_costs.csv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "            writer.writerow([cost])\n",
    "\n",
    "            f.close()\n",
    "\n",
    "        acc = np.sum(np.round(predictions) == labels) / len(labels) / 2  # half due to double-counting\n",
    "        \n",
    "        with open(f'{directory}/{name}_accs.csv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "            writer.writerow([acc])\n",
    "\n",
    "            f.close()\n",
    "        \n",
    "        with open(f'{directory}/params_raw.txt', 'w', newline='') as f:\n",
    "            paramstr = \"[\"\n",
    "            \n",
    "            for e in params:\n",
    "                paramstr += str(e) + \", \"\n",
    "\n",
    "            paramstr = paramstr[:-2] + \"]\"\n",
    "\n",
    "            f.write(paramstr)\n",
    "        \n",
    "        if name == \"dev\" or name == \"train\":\n",
    "            with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/start_time.txt', 'r') as f:\n",
    "                start_time = float(f.readline().strip())\n",
    "            \n",
    "            with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/fit_time.txt', 'w') as f:\n",
    "                f.write(str(time.time()-start_time))\n",
    "            \n",
    "            k = kwargs.get(\"k\", 0)\n",
    "            \n",
    "            if k in [130, 200, 500, 600, 700, 800, 900, 1000]:\n",
    "                with open(f'{directory}/params_{k}.txt', 'w', newline='') as f:\n",
    "                    paramstr = \"[\"\n",
    "                    \n",
    "                    for e in params:\n",
    "                        paramstr += str(e) + \", \"\n",
    "\n",
    "                    paramstr = paramstr[:-2] + \"]\"\n",
    "\n",
    "                    f.write(paramstr)\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "        return cost\n",
    "\n",
    "    return cost_fn\n",
    "\n",
    "def run_circuit_optimization(train_circuits, train_targets, dev_circuits, dev_targets, test_circuits, test_targets, experiment_name, train_params=True, load_params=False, params_saved=[], spsa_n_iter=0, k0=0):\n",
    "    # collect params\n",
    "    all_circuits = train_circuits + dev_circuits + test_circuits\n",
    "\n",
    "    # sort the symbols since they are returned as a set\n",
    "    parameters = sorted(\n",
    "        {s for circ in all_circuits for s in circ.free_symbols},\n",
    "        key=default_sort_key)\n",
    "    \n",
    "    # make prediction and cost functions\n",
    "\n",
    "    SEED = 0\n",
    "    rng = np.random.default_rng(SEED)\n",
    "\n",
    "    train_pred_fn = make_pred_fn(train_circuits, parameters, rng)\n",
    "    dev_pred_fn = make_pred_fn(dev_circuits, parameters, rng)\n",
    "    test_pred_fn = make_pred_fn(test_circuits, parameters, rng)\n",
    "\n",
    "    train_cost_fn = make_cost_fn(train_pred_fn, train_targets, '../data/experiment_results/journal/generalQC/'+experiment_name, 'train')\n",
    "    dev_cost_fn = make_cost_fn(dev_pred_fn, dev_targets, '../data/experiment_results/journal/generalQC/'+experiment_name, 'dev')\n",
    "\n",
    "    if (load_params):\n",
    "        # load params\n",
    "\n",
    "        # x0 = [params_saved[str(param)] for param in parameters]\n",
    "        x0 = params_saved\n",
    "        result = Result(x0)\n",
    "    else:\n",
    "        x0 = np.array(rng.random(len(parameters)))\n",
    "        np.random.seed(SEED)\n",
    "\n",
    "    # train params using SPSA\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/start_time.txt', 'w') as f:\n",
    "        try:\n",
    "            with open(path+'/fit_time.txt') as f2:\n",
    "                delta = float(f2.readline().strip())\n",
    "        except:\n",
    "            delta = 0\n",
    "        \n",
    "        f.write(str(start_time-delta))\n",
    "\n",
    "    # result = minimizeSPSA(train_cost_fn, x0=x0, a=spsa_a, c=spsa_c, niter=10, callback=dev_cost_fn)\n",
    "    if train_params:\n",
    "        result = myMinimizeSPSA(train_cost_fn, x0=x0, a=spsa_a, c=spsa_c, k0=k0, niter=spsa_n_iter, callback=dev_cost_fn)\n",
    "    else:\n",
    "        result = Result(x0)\n",
    "    \n",
    "    finish_time = time.time()\n",
    "\n",
    "    # with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/fit_time.txt', 'w') as f:\n",
    "    #     f.write(str(finish_time-start_time))\n",
    "\n",
    "    train_costs = []\n",
    "    train_accs = []\n",
    "    dev_costs = []\n",
    "    dev_accs = []\n",
    "\n",
    "    with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/train_costs.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            train_costs.append(float(row[0]))\n",
    "\n",
    "    with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/train_accs.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            train_accs.append(float(row[0]))\n",
    "\n",
    "    with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/dev_costs.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            dev_costs.append(float(row[0]))\n",
    "\n",
    "    with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/dev_accs.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            dev_accs.append(float(row[0]))\n",
    "\n",
    "    if train_params:\n",
    "        print(\"Fit time:\", finish_time-start_time)\n",
    "        \n",
    "        fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "        ax_tl.set_title('Training set')\n",
    "        ax_tr.set_title('Development set')\n",
    "        ax_bl.set_xlabel('Iterations')\n",
    "        ax_br.set_xlabel('Iterations')\n",
    "        ax_bl.set_ylabel('Accuracy')\n",
    "        ax_tl.set_ylabel('Loss')\n",
    "\n",
    "        colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "        ax_tl.plot(train_costs[1::2], color=next(colours))  # training evaluates twice per iteration\n",
    "        ax_bl.plot(train_accs[1::2], color=next(colours))   # so take every other entry\n",
    "        ax_tr.plot(dev_costs, color=next(colours))\n",
    "        ax_br.plot(dev_accs, color=next(colours))\n",
    "\n",
    "    # print test accuracy\n",
    "    test_cost_fn = make_cost_fn(test_pred_fn, test_targets, '../data/experiment_results/journal/generalQC/'+experiment_name, 'test')\n",
    "    test_cost_fn(result.x)\n",
    "\n",
    "    with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/test_accs.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            print('Test accuracy:', row[0])\n",
    "            test_accs = [row[0]]\n",
    "            break\n",
    "    \n",
    "    paramdict = {}\n",
    "    paramdict_print = {}\n",
    "\n",
    "    for value, parameter in zip(result.x, parameters):\n",
    "        paramdict[parameter] = value\n",
    "        paramdict_print[str(parameter)] = value\n",
    "\n",
    "    with open('../data/experiment_results/journal/generalQC/'+experiment_name+'/params.txt', 'w') as f:\n",
    "        f.write(str(paramdict_print))\n",
    "\n",
    "    # print(paramdict_print)\n",
    "\n",
    "    opt_results = {\n",
    "        \"params\": {\n",
    "            \"parameters\": parameters, \n",
    "            \"x\": result.x\n",
    "            }, \n",
    "        \"train\": {\n",
    "            \"pred_fn\": train_pred_fn, \n",
    "            \"cost_fn\": train_cost_fn, \n",
    "            \"accs\": train_accs[1::2], \n",
    "            \"costs\": train_costs[1::2]\n",
    "            }, \n",
    "        \"dev\": {\n",
    "            \"pred_fn\": dev_pred_fn, \n",
    "            \"cost_fn\": dev_cost_fn, \n",
    "            \"accs\": dev_accs, \n",
    "            \"costs\": dev_costs\n",
    "            }, \n",
    "        \"test\": {\n",
    "            \"pred_fn\": test_pred_fn, \n",
    "            \"cost_fn\": test_cost_fn, \n",
    "            \"accs\": test_accs, \n",
    "            \"costs\": None\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return opt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = run_circuit_optimization(train_circuits, train_targets, dev_circuits, dev_targets, test_circuits, test_targets, experiment_name, train_params, load_params, params_saved=params_saved, spsa_n_iter=spsa_n_iter, k0=k0)\n",
    "\n",
    "train_pred_fn, train_cost_fn, train_accs, train_costs = list(opt_results[\"train\"].values())\n",
    "dev_pred_fn, dev_cost_fn, dev_accs, dev_costs = list(opt_results[\"dev\"].values())\n",
    "test_pred_fn, test_cost_fn, test_accs, test_costs = list(opt_results[\"test\"].values())\n",
    "parameters, x = list(opt_results[\"params\"].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    print(i, \"|\", test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sentence = test_data[7]\n",
    "my_circuit = test_circuits[7]\n",
    "my_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_circuit.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decapitate_circuit(circuit):\n",
    "    from discopy import Bra, Measure\n",
    "\n",
    "    cutoff = None\n",
    "\n",
    "    for i, box in enumerate(circuit.boxes):\n",
    "        if box in [Bra, Measure, Bra(0), Bra(0, 0)]:\n",
    "            cutoff = i\n",
    "            break\n",
    "    \n",
    "    return circuit[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decapitate_circuit(my_circuit).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_saved = [0.6369616873214543, 0.2697867137638703, 0.04097352393619469, 0.016527635528529094, 0.8132702392002724, 0.9127555772777217, 0.6066357757671799, 0.7294965609839984, 0.5436249914654229, 0.9350724237877682, 0.8158535541215322, 0.002738500170148095, 0.8574042765875693, 0.033585575305464355, 0.7296554464299441, 0.17565562060255901, 0.8631789223498866, 0.5414612202490917, 0.2997118905373848, 0.42268722119765845, 0.028319671145462966, 0.12428327649956394, 0.6706244146936303, 0.6471895115742501, 0.6153851114812539, 0.38367755426188344, 0.997209935789211, 0.9808353387762301, 0.6855419844806947, 0.6504592762678163, 0.6884467305709401, 0.3889214239791038, 0.13509650502241122, 0.7214883401940817, 0.5253543224757259, 0.31024187555895566, 0.4858353588317891, 0.8894878343490003, 0.9340435159562497, 0.35779519670907023, 0.5715298307297609, 0.32186939107594215, 0.5943000301996968, 0.33791122550713326, 0.39161900052816123, 0.8902743520047923, 0.22715759353337972, 0.6231871446860424, 0.08401534358238483, 0.8326441476533978, 0.7870983074886834, 0.23936944299295215, 0.8764842308107038, 0.05856803480519435, 0.3361170605456604, 0.15027946689483906, 0.450339366649287, 0.7963242702872942, 0.23064220899374743, 0.05202130106440961, 0.4045518398215282, 0.19851304450925533, 0.0907530456191219, 0.5803323859868507, 0.2986961328189226, 0.6719948779563594, 0.1995154439682133, 0.9421131105064978, 0.36511016824482856, 0.10549527957022953, 0.6291081515397092, 0.9271545530678674, 0.440377154715784, 0.9545904936907372, 0.499895813687647, 0.42522862484907553, 0.6202134520153778, 0.9950965052353241, 0.9489436749377653, 0.4600451393090961, 0.7577288453082914, 0.49742269548761897, 0.5293121601967704, 0.7857857007138075, 0.4146558493556708, 0.7344835717887294, 0.7111428779897498, 0.9320596866133782, 0.1149326332809052, 0.7290151170763094, 0.9274239286245599, 0.9679261899246464, 0.014706304965369288, 0.8636400902455758, 0.9811950400663443, 0.9572101796109636, 0.1487640122324979, 0.972628813822955, 0.8899355557205206, 0.8223738275430704, 0.4799879238078322, 0.23237291963930384, 0.8018805787183079, 0.9235301597834695, 0.2661302722922926, 0.5389344076221869, 0.4427528289745315, 0.931017315981155, 0.040510711188434634]\n",
    "\n",
    "# params_saved = [0.3916389494310161, 0.14454979547299718, 0.08794610259057532, -0.10280728719268513, 0.892768568556111, 0.6641161553124214, 0.9016598136995068, 1.245268577542927, 0.8732294664740182, 0.4824993768064036, 0.8923679913145798, 0.31977189273447165, 1.2931782823857914, 0.2768825172846893, 0.7852485593339268, -0.15122951018647596, 1.0789514142206444, 0.5304561056536202, -0.028083591468382074, 0.3074440531058646, -0.06702624280335857, 0.2445600322921661, 1.3647967929287053, 0.7001264050699786, 0.3212899863544066, 0.7879616207119149, 0.9587458453095122, 1.0764698750215076, 0.8205837110488948, 0.547479403568829, 1.1951996296533887, 0.20047730551935838, 0.423243575636949, 0.4807388700383679, 0.9772918654323084, -0.08480931633169364, 0.41973757001186335, 1.2935029463303167, 1.297796202944872, 0.1235036473284651, 0.8292545726056161, 0.5256354386300907, 0.10562191757425322, 0.38201279428948215, 0.5550677313142515, 1.2567157025229352, 0.39082855678862144, 0.7475086311060858, -0.40734174860395606, 1.4243887951265934, 0.5344935105828672, 0.4929906924150636, 1.466220148303609, 0.112819879263767, 0.2714965608408019, 0.23685629415335224, 0.8359064846486968, 0.21001771067889619, 0.10041861699886803, -0.4768749337492845, 0.7407969536287277, 0.28585079765615345, 0.21746606479263747, 0.21119967120133792, -0.13155454757716056, 0.5784470856558313, 0.05396553384746348, 0.9494508313640194, 0.04725042909647588, -0.9599467119386298, 1.0614658554434508, 0.9604451200914907, 0.15962440419386775, 0.9356401267570099, -0.10175095202671093, 0.6450848791988285, 0.7369923060120671, 0.40114589593781896, 1.4178328954999273, 0.6925633013881465, 0.4436912735527206, 0.3250121857605643, 0.8722074944497472, 0.8524082887624035, 0.226555400922005, 1.0875181692752465, 0.4706374207790644, 0.8427691581441736, 0.33328424428096187, 0.7175800739513822, 1.499625469156253, 0.4317647167286927, 0.2124684997913851, 0.8015907756496712, 1.8585376306660066, 0.7090288565793986, 0.2825089504690953, 0.578440025774433, 1.1249455208443424, 1.1928559475432128, 1.0057551394912103, 0.43294922925125295, 0.5828598387821716, 0.9543088014807183, 0.621829563681839, 0.1494358665858202, 0.21344650282951988, 0.8174463295385852, 0.43950139240434655]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits = train_circuits + dev_circuits + test_circuits\n",
    "parameters = sorted(\n",
    "    {s for circ in all_circuits for s in circ.free_symbols},\n",
    "    key=default_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "\n",
    "for p, v in zip(parameters, params_saved):\n",
    "    params_dict[str(p)] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "all_circuit_fns = {}\n",
    "all_predictions = {}\n",
    "\n",
    "for name in [\"train\", \"dev\", \"test\"]:\n",
    "    print(name)\n",
    "\n",
    "    SEED = 0\n",
    "    rng = np.random.default_rng(SEED)\n",
    "\n",
    "    if name == \"train\":\n",
    "        circuits = train_circuits\n",
    "    elif name == \"dev\":\n",
    "        circuits = dev_circuits\n",
    "    else:\n",
    "        circuits = test_circuits\n",
    "\n",
    "    measured_circuits = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuits]\n",
    "    circuit_fns = [c.lambdify(*parameters) for c in measured_circuits]\n",
    "\n",
    "    outputs = Circuit.eval(*(c_fn(*params_saved) for c_fn in circuit_fns),\n",
    "                                **backend_config, seed=randint(rng))\n",
    "    results = np.array([normalise(output.array) for output in outputs])\n",
    "    predictions = np.round(results)\n",
    "\n",
    "    all_results[name] = results\n",
    "    all_circuit_fns[name] = [c_fn(*params_saved) for c_fn in circuit_fns]\n",
    "    all_predictions[name] = predictions\n",
    "\n",
    "    with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/{name}_800_outputs.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        for e in results:\n",
    "            writer.writerow(e)\n",
    "\n",
    "        f.close()\n",
    "    \n",
    "    with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/{name}_800_predictions.txt', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        for e in predictions:\n",
    "            writer.writerow([int(e[0])])\n",
    "\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results, dev_results, test_results = [all_results[name] for name in [\"train\", \"dev\", \"test\"]]\n",
    "train_circ_fns, dev_circ_fns, test_circ_fns = [all_circuit_fns[name] for name in [\"train\", \"dev\", \"test\"]]\n",
    "train_preds, dev_preds, test_preds = [all_predictions[name] for name in [\"train\", \"dev\", \"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_circ_fns[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (pred, target) in enumerate(zip(train_preds, train_targets)):    \n",
    "    if int(pred[0]) != target[0]:\n",
    "        print(\"---\")\n",
    "        print(train_results[i])\n",
    "        print(train_targets[i])\n",
    "        print(train_data[i])\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in enumerate(train_results):\n",
    "    # if abs(res[0]-res[1]) <= 0.1:\n",
    "    if \" had \" in train_data[i]:\n",
    "        print(\"---\")\n",
    "        print(train_data[i])\n",
    "        print(res)\n",
    "        print(train_targets[i])\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_circuits[70].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[349]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_saved = [1.3505649493072467, -0.14966328435185, 0.04675537879798401, -0.0015354611799713639, 0.8467703608674717, 1.5964349654020935, 0.9415552599593355, 0.7916802060431765, 0.09940955754857185, 1.3473293118007097, 0.5579013343383226, -0.2679104960784575, 0.3776135427626039, 0.62703035023651, 0.4285010663953328, 0.019792381213966686, 0.940842946083086, 0.33781388773672416, 0.8487456927074848, 0.7556821018373534, -0.5608258781490134, 0.36476364832952235, 1.0737220311034188, -0.1124067666176007, 0.08191140893146531, -0.3822700356542936, 1.7675583352903093, 1.157455792341757, 0.17848596573971048, 0.4316137952186831, 0.8206557377751482, 0.6847553524509737, 0.05400777268978768, 1.2013720181631076, 0.28904507119386325, 0.06465854055487004, -0.09416797215962379, 1.051771804895434, 0.7506276718251563, 0.3884711100982121, 0.8482724716958543, 0.8149804380340482, 0.7896084168659374, 0.3496117177218967, 0.6011503910365614, 1.5729679680184632, 0.9792834796934351, 0.41266904602145826, -0.26523798248283115, 0.29819378568686317, 0.9586926117734706, 0.40703254844620307, 1.0296364797336521, 0.17863789971485083, -0.008456234920267822, 0.48771312748188433, 0.05076209488566123, 1.3298132342611912, -0.5878522477674955, 0.4067109276060562, 0.4423094947759354, 0.32301125698163086, 0.593848336018743, 0.6526038095556363, -0.4966519491527389, 0.6415696668260122, 0.7906445725342086, 1.5599899677343447, 0.558077628311284, -0.11041397551907499, 0.5957225862423388, 1.1732862757098548, -0.2265062280939964, 1.5044824049304453, -0.0533738041658748, 0.33420598890680564, 1.196245190159652, 0.9697961143224758, 0.6533425442624752, 0.08669834541405962, 0.48807237501014855, 1.0485106762146703, 1.0621443507152275, 0.9252129972582814, 0.9548661806967234, 0.9692520279388916, 1.170143153963476, 1.4122822854880106, 0.46545972319331497, 0.630801420187417, 0.40534540594920576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([-0.4323784625156951, -0.11620727905897381, 1.4973383602037345, -0.03854524403780189, 2.0374233492687566, 1.5140237527641283, 1.444298082326406, 2.1433243163412987, 0.3335877898205426, 2.322767082131911, 0.4137332206525631, 0.9370938253749876, -1.2186411867362663, 2.182970888144907, -0.30001726549982, -1.280010131273, -1.240420762380745, 0.25559251653212034, 1.198871358231981, 1.9466018631131183, -0.8461817674872734, 0.4044083767217057, 0.4135888107223832, 0.680697621675467, 0.6763327177395548, 0.12400205592268741, 0.28472984206223273, 1.46286381036896, -0.6846077857024961, -0.12348498940846518, 0.00042752158879726457, 0.7786479966675994, 0.3762707285015985, 1.8339876221039906, 0.7546945970133587, 1.2954743513724676, 1.1189879516280032, 1.554731855398106, 0.5459763035516325, 0.5630198919879377, 0.2497657568660185, 1.553089188814977, 0.5399929337991567, 2.1394608914569337, 0.8320637623953138, 1.0208125581827399, 1.746891430398501, 0.24297280615422648, 1.067313822283161, 0.1683503575122933, 0.9371614593815363, 1.7769052411803572, 0.9394992999866614, -0.5503801207612324, 1.7986479269174476, -1.8933465051454728, 2.4967528801550394, -0.7881772805743563, 1.4935987998906781, 1.6098798393244347, 0.33431967894069914, 2.4122213458244506, -0.4241483031454979, 1.9589553387802787, -2.3777264666778306, 1.134318927803079, -0.4632077775409472, -0.6584494020466984, 1.2043861700286573, -0.4940586421065911, 0.9192688948268928, 1.7768409627853985, 0.28010773904347763, 1.3921682727516012, 1.1541033767646645, 1.8481505071177837, -0.9686394356598356, -1.2205812206499043, -1.6232213268536064, 1.076716880418417, -1.0861949753754054, 1.0666182679966156, -0.32709247539028496, 2.546949283251263, 1.9340185332827495, 0.7880610218763398, 2.2087825995359056, 0.9496007155089805, 1.660665072847281, 1.6037007145170072, -0.32614022200846493, 0.2785689151676384, -1.4112641689861376, 0.9994077821950809, 1.074792322801971, 2.1462787111490176, 1.4864804880560976, 2.2883699471586594, 2.231039500129616, 1.5690108162873693, 2.2361477935512495, 2.3312252529554565, 0.540632910160765, 1.757678638031757, 0.9531660845886505, 0.29737005461364824, 1.2059746671700204, 0.6805532063796766, 0.9466141365832856, -1.0306382446135176, 0.23746438536006195, 0.5912289692951731, 0.9248615786181282, 0.507395077983918, -0.22286551184693051, -0.06319606663790629, -0.38467648961049294, -0.47522524986953263, 1.1553997789292172, 0.8892035580458035, 0.03433505232537521, 1.4620344402677796, 1.4226925989502197, 1.4533165980597809, 0.1490223645182724, 1.4381172952957462, 1.9567432117533174, -1.2339937261615797, 2.4042374496602035, 0.16502046721425165, -0.7444476471819594, 2.8722271304534432, -0.1872171195862206, -0.19847315047376476, -0.325611071573202, 0.0025698395608431575, -0.26460246353308897, -0.8412145294390354, 3.722862825102493, 0.05803777520599274, -0.47814666399877925, -0.8872218006787898, -0.723914843506589, 0.18728071831472212, 1.080763130515984, -0.09097375156189948, 0.5979815125008658, -0.4053213618210365, 0.7912537445157382, 2.1956785936293564, 0.0021992901764217344, -0.39226801095727115, -1.1430062220161248, 1.1981524648966535, 1.584071930562724, -1.035146154883806, 0.32146252719321355, -0.7958358825849352, 0.9589534659669602, -0.3542663327509362, -0.09288521558240805, 0.9151596097780086, -0.32613162288520403, 1.6451724304389659, 2.504567920965232, 1.7224522924843315, 0.7285976955128899, 0.9316765198089327, 0.33086112720306826, 1.6033826024436015, 1.586669864976121, 0.35068102693721825, 1.1980971864517747, 1.3237131162195874, 0.6923241535777191, 2.3202370184585135, -1.078664822999987, 1.7837227824618789, 0.9272313502715341, 1.001720739942008, 0.7434753728855283, -1.5536427543777362, -0.5176451818377981, 0.915098341753962, 0.39761713014185973, -0.2220904898148792, 1.328753426100933, 2.1545630544942407, -0.2156130854540624, 0.5472633175558026, 1.7032622203717578, 0.3730334279936519, 0.4966717089488064, 1.8550415352638963, 1.6400132870278883, 1.3274182228397717, 0.9818660429252556, 1.9107850554833987, 0.8246507451119509, -0.5030432429482791, -0.3836630185226968, 0.11544700254130628, 1.1854909308034505, -1.2235860634870668, -1.7008885633802162, -0.0067929505246507, 0.7261626421866967, -0.5436919042776467, 1.3099957445173809, 0.2988125014657036, 0.9426728001640396, 0.3068642540757601, 1.181971665006179, 1.1877062965701426, 2.377159844943775, -0.5108107832602529, 0.748265813584112, 1.2961912770589685])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = {'amaz__n.r@s_0': 1.3548387429641024, 'amaz__n.r@s_1': -0.40968958996573457, 'amaz__n@n.l_0': 0.46446769165749563, 'amaz__n@n.l_1': -0.7897502222614423, 'aw__n.r@s_0': 0.19890282546648633, 'aw__n.r@s_1': 0.7505664359118243, 'aw__n@n.l_0': -0.13677572719082645, 'aw__n@n.l_1': 1.1432242545339935, 'bad__n.r@s_0': 0.818491469732785, 'bad__n.r@s_1': 1.3232750569429426, 'bad__n@n.l_0': 0.309841347177341, 'bad__n@n.l_1': 0.7369628206871559, 'bland__n.r@s_0': 0.5690313574389705, 'bland__n.r@s_1': -0.6009589913097046, 'bland__n@n.l_0': 0.7095547429955995, 'bland__n@n.l_1': 0.6482175256399125, 'cafe__n_0': 0.5563202593375558, 'cafe__n_1': 1.1102817042496054, 'cafe__n_2': 0.7869632558429331, 'cook__n.r@s@n.l_0': -0.18361276867135554, 'cook__n.r@s@n.l_1': 0.8894794651507758, 'cook__n.r@s@n.l_2': -0.5676865473678465, 'cook__n_0': -0.0871869484560759, 'cook__n_1': 1.2751344781156584, 'cook__n_2': 1.2346011446565368, 'delici__n.r@s_0': -0.3423389184605571, 'delici__n.r@s_1': 1.6282186553162734, 'delici__n@n.l_0': 0.24570905491932157, 'delici__n@n.l_1': 1.5912927597039428, 'dish__n_0': 0.8948996173029191, 'dish__n_1': 1.4077772467661651, 'dish__n_2': 0.16687831072824214, 'dislik__n.r@s@n.l_0': 0.8829097040054295, 'dislik__n.r@s@n.l_1': 0.00532752405338696, 'dislik__n.r@s@n.l_2': 1.259579185412011, 'excel__n.r@s_0': 1.2005939772946728, 'excel__n.r@s_1': 1.4495307385940652, 'excel__n@n.l_0': -0.15977988988759687, 'excel__n@n.l_1': 1.5698727473821368, 'fast__n.r@s_0': -0.5676401997916904, 'fast__n.r@s_1': 0.9011817671038247, 'fast__n@n.l_0': -0.2447996461074705, 'fast__n@n.l_1': 1.2094808549154972, 'food__n_0': 0.7984729419032632, 'food__n_1': 0.6620077416706938, 'food__n_2': 1.8116695287930913, 'foodservic__n_0': 0.7485384081177493, 'foodservic__n_1': -0.25380560227309784, 'foodservic__n_2': 1.0551077244302316, 'good__n.r@s_0': 1.4939861404294996, 'good__n.r@s_1': 0.6021445441545323, 'good__n@n.l_0': 1.1655299551499223, 'good__n@n.l_1': 1.1612402462796767, 'great__n.r@s_0': 0.4161791483178209, 'great__n.r@s_1': -0.7386298346601656, 'great__n@n.l_0': 0.7100167408127303, 'great__n@n.l_1': 0.6649127362322125, 'had__n.r@s@n.l_0': 0.2757785639962078, 'had__n.r@s@n.l_1': 1.0716603778022131, 'had__n.r@s@n.l_2': -0.4846258128685169, 'hate__n.r@s@n.l_0': 0.9555105420258994, 'hate__n.r@s@n.l_1': 0.7385129608573815, 'hate__n.r@s@n.l_2': -0.9057692650143729, 'horribl__n.r@s_0': -0.14614460680956895, 'horribl__n.r@s_1': 1.0608822627791792, 'horribl__n@n.l_0': 1.3187968187672219, 'horribl__n@n.l_1': 1.211942158170499, 'i__n_0': 0.21338768301272723, 'i__n_1': -0.0945974008880786, 'i__n_2': 0.5127230302020738, 'impecc__n.r@s_0': 1.1739587942015013, 'impecc__n.r@s_1': 1.4745559646369295, 'impecc__n@n.l_0': 0.7492396312356675, 'impecc__n@n.l_1': 1.7215177165413316, 'kind__n.r@s_0': 0.11764097689842447, 'kind__n.r@s_1': 1.353241630848178, 'kind__n@n.l_0': -0.4370549142130727, 'kind__n@n.l_1': 1.4926648400944056, 'like__n.r@s@n.l_0': 1.440179378317805, 'like__n.r@s@n.l_1': 0.9496250236165473, 'like__n.r@s@n.l_2': 0.3311509913979628, 'lousi__n.r@s_0': -0.5957916438516884, 'lousi__n.r@s_1': 0.3389969562821663, 'lousi__n@n.l_0': 1.462202672430934, 'lousi__n@n.l_1': 1.0086413896754833, 'love__n.r@s@n.l_0': -0.0057825184822388595, 'love__n.r@s@n.l_1': 0.19527395265870492, 'love__n.r@s@n.l_2': 0.018917314579316745, 'meal__n_0': -0.47592664474156304, 'meal__n_1': 1.4522443155636653, 'meal__n_2': 1.7279864860411926, 'nice__n.r@s_0': 1.364573740293923, 'nice__n.r@s_1': -0.7172955437720991, 'nice__n@n.l_0': 0.5093513355804887, 'nice__n@n.l_1': 1.4903730455737827, 'poor__n.r@s_0': 0.3004832870566322, 'poor__n.r@s_1': 0.9269724385652787, 'poor__n@n.l_0': 1.3905779791901631, 'poor__n@n.l_1': 0.14381426031641034, 'restaur__n_0': 1.3387837858870708, 'restaur__n_1': -0.4508138074464033, 'restaur__n_2': -0.32055348757053803, 'rude__n.r@s_0': 0.4711446798352404, 'rude__n.r@s_1': 0.2842256503448778, 'rude__n@n.l_0': 1.108575011018078, 'rude__n@n.l_1': 1.0144538904889677, 'servic__n_0': 1.4036251888656066, 'servic__n_1': 0.401340086563827, 'servic__n_2': -0.29059213196627265, 'show__n.r@s@n.l_0': 0.38355023800214605, 'show__n.r@s@n.l_1': 0.9672719364401363, 'show__n.r@s@n.l_2': -0.5009609769615575, 'slow__n.r@s_0': -0.1742595099873864, 'slow__n.r@s_1': -0.4854346057870236, 'slow__n@n.l_0': -0.16757109120975303, 'slow__n@n.l_1': 1.1282247274923358, 'staff__n_0': 1.3397285067597315, 'staff__n_1': -0.5514125961016505, 'staff__n_2': 0.6246033807705262, 'tasti__n.r@s_0': 0.7133738453446998, 'tasti__n.r@s_1': 0.6206325760326519, 'tasti__n@n.l_0': 1.135508931039068, 'tasti__n@n.l_1': 0.22839160241876752, 'terribl__n.r@s_0': 0.10107926501439181, 'terribl__n.r@s_1': 1.113422009652562, 'terribl__n@n.l_0': 0.1729725509900462, 'terribl__n@n.l_1': 0.7887820793671689, 'unappet__n.r@s_0': -0.9174708518668786, 'unappet__n.r@s_1': -0.8149983148924347, 'unappet__n@n.l_0': 0.17682451123898327, 'unappet__n@n.l_1': 1.3270151715747143, 'unpleas__n.r@s_0': 0.6928653739285406, 'unpleas__n.r@s_1': 1.4960003503961838, 'unpleas__n@n.l_0': 0.254206322992376, 'unpleas__n@n.l_1': 0.8170090820074032, 'waiter__n_0': -0.343463890393225, 'waiter__n_1': 1.4355148049816058, 'waiter__n_2': -0.0833260818781938, 'yummi__n.r@s_0': 0.7206916533045415, 'yummi__n.r@s_1': 0.732688436038152, 'yummi__n@n.l_0': 0.9966147569363768, 'yummi__n@n.l_1': 0.8315387990620471}\n",
    "\n",
    "print(list(var.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noisyopt import minimizeSPSA\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import default_sort_key\n",
    "import gc\n",
    "\n",
    "test_name = \"test_800\"\n",
    "\n",
    "# collect params\n",
    "all_circuits = train_circuits + dev_circuits + test_circuits\n",
    "\n",
    "# sort the symbols since they are returned as a set\n",
    "parameters = sorted(\n",
    "    {s for circ in all_circuits for s in circ.free_symbols},\n",
    "    key=default_sort_key)\n",
    "\n",
    "# make prediction and cost functions\n",
    "\n",
    "SEED = 0\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "test_pred_fn = make_pred_fn(test_circuits, parameters, rng)\n",
    "\n",
    "x0 = params_saved\n",
    "result = Result(x0)\n",
    "\n",
    "# print test accuracy\n",
    "test_cost_fn = make_cost_fn(test_pred_fn, test_targets, '../data/experiment_results/journal/generalQC/'+experiment_name, test_name)\n",
    "test_cost_fn(result.x)\n",
    "\n",
    "with open(f'../data/experiment_results/journal/generalQC/{experiment_name}/{test_name}_accs.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "    for row in csv_reader:\n",
    "        print('Test accuracy:', row[0])\n",
    "        test_accs = [row[0]]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_circuits[89].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleSA 3\n",
    "# H-CRx (nouns) 16\n",
    "# Rx-CX (nouns) 16\n",
    "# Rx-CRz (nouns) 26\n",
    "# H-CRx 10\n",
    "# Rx-CX 10\n",
    "# Rx-CRz 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_circuits[349].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
